{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "dataDir = Path.cwd().parent.parent.parent/'Data/processed'\n",
    "ts_dataset = pd.read_csv(dataDir/\"learner_118_new_meanTimeCost.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_timeDelta_Seconds__sum_of_reoccurring_data_points</th>\n",
       "      <th>Total_timeDelta_Seconds__sum_of_reoccurring_values</th>\n",
       "      <th>Total_timeDelta_Seconds__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"</th>\n",
       "      <th>Total_timeDelta_Seconds__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"min\"</th>\n",
       "      <th>Total_timeDelta_Seconds__autocorrelation__lag_9</th>\n",
       "      <th>Total_timeDelta_Seconds__sample_entropy</th>\n",
       "      <th>Total_timeDelta_Seconds__autocorrelation__lag_5</th>\n",
       "      <th>Total_timeDelta_Seconds__fft_coefficient__attr_\"real\"__coeff_60</th>\n",
       "      <th>Total_timeDelta_Seconds__cwt_coefficients__coeff_13__w_2__widths_(2, 5, 10, 20)</th>\n",
       "      <th>milking_times__number_peaks__n_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_MilkProduction__cwt_coefficients__coeff_8__w_5__widths_(2, 5, 10, 20)</th>\n",
       "      <th>Total_timeDelta_Seconds__last_location_of_minimum</th>\n",
       "      <th>DaysInMilk__linear_trend__attr_\"slope\"</th>\n",
       "      <th>milking_times__fft_coefficient__attr_\"imag\"__coeff_3</th>\n",
       "      <th>milking_times__number_peaks__n_1</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.148938</td>\n",
       "      <td>-0.137108</td>\n",
       "      <td>-0.599549</td>\n",
       "      <td>-0.037466</td>\n",
       "      <td>-0.858143</td>\n",
       "      <td>0.571451</td>\n",
       "      <td>-0.102382</td>\n",
       "      <td>-0.043234</td>\n",
       "      <td>0.697043</td>\n",
       "      <td>-0.673878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253646</td>\n",
       "      <td>0.650171</td>\n",
       "      <td>-0.224828</td>\n",
       "      <td>-1.208569</td>\n",
       "      <td>-0.032362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164452</td>\n",
       "      <td>0.181009</td>\n",
       "      <td>-0.423940</td>\n",
       "      <td>0.132696</td>\n",
       "      <td>0.290556</td>\n",
       "      <td>-1.856551</td>\n",
       "      <td>1.626652</td>\n",
       "      <td>-0.984812</td>\n",
       "      <td>-1.526357</td>\n",
       "      <td>-1.237833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341874</td>\n",
       "      <td>-0.431548</td>\n",
       "      <td>-0.224552</td>\n",
       "      <td>0.208745</td>\n",
       "      <td>1.025141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.765083</td>\n",
       "      <td>0.624520</td>\n",
       "      <td>-0.740572</td>\n",
       "      <td>0.073102</td>\n",
       "      <td>-0.591320</td>\n",
       "      <td>0.877939</td>\n",
       "      <td>0.168240</td>\n",
       "      <td>0.029852</td>\n",
       "      <td>0.398983</td>\n",
       "      <td>-1.237833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905989</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>-0.192719</td>\n",
       "      <td>-1.336781</td>\n",
       "      <td>0.026388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.238420</td>\n",
       "      <td>-0.227939</td>\n",
       "      <td>-0.704557</td>\n",
       "      <td>-0.460532</td>\n",
       "      <td>-0.161239</td>\n",
       "      <td>-0.821921</td>\n",
       "      <td>0.429063</td>\n",
       "      <td>1.222054</td>\n",
       "      <td>0.490578</td>\n",
       "      <td>-1.237833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011581</td>\n",
       "      <td>1.085493</td>\n",
       "      <td>0.021291</td>\n",
       "      <td>0.417031</td>\n",
       "      <td>-0.619864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.531245</td>\n",
       "      <td>-0.525181</td>\n",
       "      <td>1.574367</td>\n",
       "      <td>0.517369</td>\n",
       "      <td>0.237840</td>\n",
       "      <td>-1.208224</td>\n",
       "      <td>0.077915</td>\n",
       "      <td>0.536305</td>\n",
       "      <td>0.439460</td>\n",
       "      <td>-1.801787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488084</td>\n",
       "      <td>-1.120431</td>\n",
       "      <td>0.518167</td>\n",
       "      <td>0.041955</td>\n",
       "      <td>-1.148616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.092416</td>\n",
       "      <td>-0.079734</td>\n",
       "      <td>2.300936</td>\n",
       "      <td>0.753258</td>\n",
       "      <td>-1.369126</td>\n",
       "      <td>-1.027787</td>\n",
       "      <td>0.164207</td>\n",
       "      <td>-0.024596</td>\n",
       "      <td>0.574318</td>\n",
       "      <td>-0.955855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.586410</td>\n",
       "      <td>-1.221363</td>\n",
       "      <td>0.371932</td>\n",
       "      <td>0.474052</td>\n",
       "      <td>-1.383617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.581501</td>\n",
       "      <td>-0.576195</td>\n",
       "      <td>0.706650</td>\n",
       "      <td>-0.003036</td>\n",
       "      <td>-1.223249</td>\n",
       "      <td>1.130458</td>\n",
       "      <td>-1.198307</td>\n",
       "      <td>-0.725614</td>\n",
       "      <td>1.201214</td>\n",
       "      <td>-0.391901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468305</td>\n",
       "      <td>1.219352</td>\n",
       "      <td>-0.224828</td>\n",
       "      <td>-0.423797</td>\n",
       "      <td>-0.443614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.218944</td>\n",
       "      <td>-0.208170</td>\n",
       "      <td>-0.005124</td>\n",
       "      <td>-0.394438</td>\n",
       "      <td>-0.364924</td>\n",
       "      <td>0.066710</td>\n",
       "      <td>-0.624508</td>\n",
       "      <td>-0.226075</td>\n",
       "      <td>1.307687</td>\n",
       "      <td>0.172054</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211432</td>\n",
       "      <td>1.204985</td>\n",
       "      <td>-0.224828</td>\n",
       "      <td>-0.369839</td>\n",
       "      <td>0.790140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-0.082474</td>\n",
       "      <td>-0.069641</td>\n",
       "      <td>-0.462500</td>\n",
       "      <td>0.350315</td>\n",
       "      <td>-0.881258</td>\n",
       "      <td>0.214894</td>\n",
       "      <td>-0.789106</td>\n",
       "      <td>-0.951098</td>\n",
       "      <td>0.583930</td>\n",
       "      <td>1.299963</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.067888</td>\n",
       "      <td>0.379210</td>\n",
       "      <td>-0.217892</td>\n",
       "      <td>0.624378</td>\n",
       "      <td>-0.208613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-0.112574</td>\n",
       "      <td>-0.102545</td>\n",
       "      <td>-0.253568</td>\n",
       "      <td>-0.040030</td>\n",
       "      <td>-0.859478</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>-1.090841</td>\n",
       "      <td>1.146818</td>\n",
       "      <td>1.069993</td>\n",
       "      <td>0.736009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573606</td>\n",
       "      <td>1.218848</td>\n",
       "      <td>-0.224828</td>\n",
       "      <td>-1.003639</td>\n",
       "      <td>0.907641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total_timeDelta_Seconds__sum_of_reoccurring_data_points  \\\n",
       "id                                                             \n",
       "1                                            -0.148938         \n",
       "2                                             0.164452         \n",
       "3                                             0.765083         \n",
       "4                                            -0.238420         \n",
       "5                                            -0.531245         \n",
       "..                                                 ...         \n",
       "114                                          -0.092416         \n",
       "115                                          -0.581501         \n",
       "116                                          -0.218944         \n",
       "117                                          -0.082474         \n",
       "118                                          -0.112574         \n",
       "\n",
       "     Total_timeDelta_Seconds__sum_of_reoccurring_values  \\\n",
       "id                                                        \n",
       "1                                            -0.137108    \n",
       "2                                             0.181009    \n",
       "3                                             0.624520    \n",
       "4                                            -0.227939    \n",
       "5                                            -0.525181    \n",
       "..                                                 ...    \n",
       "114                                          -0.079734    \n",
       "115                                          -0.576195    \n",
       "116                                          -0.208170    \n",
       "117                                          -0.069641    \n",
       "118                                          -0.102545    \n",
       "\n",
       "     Total_timeDelta_Seconds__agg_linear_trend__attr_\"rvalue\"__chunk_len_10__f_agg_\"mean\"  \\\n",
       "id                                                                                          \n",
       "1                                            -0.599549                                      \n",
       "2                                            -0.423940                                      \n",
       "3                                            -0.740572                                      \n",
       "4                                            -0.704557                                      \n",
       "5                                             1.574367                                      \n",
       "..                                                 ...                                      \n",
       "114                                           2.300936                                      \n",
       "115                                           0.706650                                      \n",
       "116                                          -0.005124                                      \n",
       "117                                          -0.462500                                      \n",
       "118                                          -0.253568                                      \n",
       "\n",
       "     Total_timeDelta_Seconds__agg_linear_trend__attr_\"slope\"__chunk_len_10__f_agg_\"min\"  \\\n",
       "id                                                                                        \n",
       "1                                            -0.037466                                    \n",
       "2                                             0.132696                                    \n",
       "3                                             0.073102                                    \n",
       "4                                            -0.460532                                    \n",
       "5                                             0.517369                                    \n",
       "..                                                 ...                                    \n",
       "114                                           0.753258                                    \n",
       "115                                          -0.003036                                    \n",
       "116                                          -0.394438                                    \n",
       "117                                           0.350315                                    \n",
       "118                                          -0.040030                                    \n",
       "\n",
       "     Total_timeDelta_Seconds__autocorrelation__lag_9  \\\n",
       "id                                                     \n",
       "1                                          -0.858143   \n",
       "2                                           0.290556   \n",
       "3                                          -0.591320   \n",
       "4                                          -0.161239   \n",
       "5                                           0.237840   \n",
       "..                                               ...   \n",
       "114                                        -1.369126   \n",
       "115                                        -1.223249   \n",
       "116                                        -0.364924   \n",
       "117                                        -0.881258   \n",
       "118                                        -0.859478   \n",
       "\n",
       "     Total_timeDelta_Seconds__sample_entropy  \\\n",
       "id                                             \n",
       "1                                   0.571451   \n",
       "2                                  -1.856551   \n",
       "3                                   0.877939   \n",
       "4                                  -0.821921   \n",
       "5                                  -1.208224   \n",
       "..                                       ...   \n",
       "114                                -1.027787   \n",
       "115                                 1.130458   \n",
       "116                                 0.066710   \n",
       "117                                 0.214894   \n",
       "118                                 0.594435   \n",
       "\n",
       "     Total_timeDelta_Seconds__autocorrelation__lag_5  \\\n",
       "id                                                     \n",
       "1                                          -0.102382   \n",
       "2                                           1.626652   \n",
       "3                                           0.168240   \n",
       "4                                           0.429063   \n",
       "5                                           0.077915   \n",
       "..                                               ...   \n",
       "114                                         0.164207   \n",
       "115                                        -1.198307   \n",
       "116                                        -0.624508   \n",
       "117                                        -0.789106   \n",
       "118                                        -1.090841   \n",
       "\n",
       "     Total_timeDelta_Seconds__fft_coefficient__attr_\"real\"__coeff_60  \\\n",
       "id                                                                     \n",
       "1                                            -0.043234                 \n",
       "2                                            -0.984812                 \n",
       "3                                             0.029852                 \n",
       "4                                             1.222054                 \n",
       "5                                             0.536305                 \n",
       "..                                                 ...                 \n",
       "114                                          -0.024596                 \n",
       "115                                          -0.725614                 \n",
       "116                                          -0.226075                 \n",
       "117                                          -0.951098                 \n",
       "118                                           1.146818                 \n",
       "\n",
       "     Total_timeDelta_Seconds__cwt_coefficients__coeff_13__w_2__widths_(2, 5, 10, 20)  \\\n",
       "id                                                                                     \n",
       "1                                             0.697043                                 \n",
       "2                                            -1.526357                                 \n",
       "3                                             0.398983                                 \n",
       "4                                             0.490578                                 \n",
       "5                                             0.439460                                 \n",
       "..                                                 ...                                 \n",
       "114                                           0.574318                                 \n",
       "115                                           1.201214                                 \n",
       "116                                           1.307687                                 \n",
       "117                                           0.583930                                 \n",
       "118                                           1.069993                                 \n",
       "\n",
       "     milking_times__number_peaks__n_5  ...  \\\n",
       "id                                     ...   \n",
       "1                           -0.673878  ...   \n",
       "2                           -1.237833  ...   \n",
       "3                           -1.237833  ...   \n",
       "4                           -1.237833  ...   \n",
       "5                           -1.801787  ...   \n",
       "..                                ...  ...   \n",
       "114                         -0.955855  ...   \n",
       "115                         -0.391901  ...   \n",
       "116                          0.172054  ...   \n",
       "117                          1.299963  ...   \n",
       "118                          0.736009  ...   \n",
       "\n",
       "     Total_MilkProduction__cwt_coefficients__coeff_8__w_5__widths_(2, 5, 10, 20)  \\\n",
       "id                                                                                 \n",
       "1                                             0.253646                             \n",
       "2                                            -0.341874                             \n",
       "3                                             2.905989                             \n",
       "4                                            -0.011581                             \n",
       "5                                            -0.488084                             \n",
       "..                                                 ...                             \n",
       "114                                          -0.586410                             \n",
       "115                                           0.468305                             \n",
       "116                                           1.211432                             \n",
       "117                                          -1.067888                             \n",
       "118                                           0.573606                             \n",
       "\n",
       "     Total_timeDelta_Seconds__last_location_of_minimum  \\\n",
       "id                                                       \n",
       "1                                             0.650171   \n",
       "2                                            -0.431548   \n",
       "3                                             0.907542   \n",
       "4                                             1.085493   \n",
       "5                                            -1.120431   \n",
       "..                                                 ...   \n",
       "114                                          -1.221363   \n",
       "115                                           1.219352   \n",
       "116                                           1.204985   \n",
       "117                                           0.379210   \n",
       "118                                           1.218848   \n",
       "\n",
       "     DaysInMilk__linear_trend__attr_\"slope\"  \\\n",
       "id                                            \n",
       "1                                 -0.224828   \n",
       "2                                 -0.224552   \n",
       "3                                 -0.192719   \n",
       "4                                  0.021291   \n",
       "5                                  0.518167   \n",
       "..                                      ...   \n",
       "114                                0.371932   \n",
       "115                               -0.224828   \n",
       "116                               -0.224828   \n",
       "117                               -0.217892   \n",
       "118                               -0.224828   \n",
       "\n",
       "     milking_times__fft_coefficient__attr_\"imag\"__coeff_3  \\\n",
       "id                                                          \n",
       "1                                            -1.208569      \n",
       "2                                             0.208745      \n",
       "3                                            -1.336781      \n",
       "4                                             0.417031      \n",
       "5                                             0.041955      \n",
       "..                                                 ...      \n",
       "114                                           0.474052      \n",
       "115                                          -0.423797      \n",
       "116                                          -0.369839      \n",
       "117                                           0.624378      \n",
       "118                                          -1.003639      \n",
       "\n",
       "     milking_times__number_peaks__n_1  BreedName_1  BreedName_2  BreedName_4  \\\n",
       "id                                                                             \n",
       "1                           -0.032362          1.0          0.0          0.0   \n",
       "2                            1.025141          0.0          1.0          0.0   \n",
       "3                            0.026388          1.0          0.0          0.0   \n",
       "4                           -0.619864          0.0          0.0          1.0   \n",
       "5                           -1.148616          0.0          1.0          0.0   \n",
       "..                                ...          ...          ...          ...   \n",
       "114                         -1.383617          0.0          1.0          0.0   \n",
       "115                         -0.443614          1.0          0.0          0.0   \n",
       "116                          0.790140          0.0          1.0          0.0   \n",
       "117                         -0.208613          1.0          0.0          0.0   \n",
       "118                          0.907641          1.0          0.0          0.0   \n",
       "\n",
       "     BreedName_99  label  \n",
       "id                        \n",
       "1             0.0      1  \n",
       "2             0.0      0  \n",
       "3             0.0      1  \n",
       "4             0.0      0  \n",
       "5             0.0      0  \n",
       "..            ...    ...  \n",
       "114           0.0      1  \n",
       "115           0.0      1  \n",
       "116           0.0      0  \n",
       "117           0.0      1  \n",
       "118           0.0      1  \n",
       "\n",
       "[118 rows x 105 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha\": [1e0, 1e-1, 1e-2, 1e-3],\n",
    "              \"kernel\": [ExpSineSquared(l, p)\n",
    "                         for l in np.logspace(-2, 2, 10)\n",
    "                         for p in np.logspace(0, 2, 10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "18 fits failed out of a total of 72.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 70-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 73-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 66-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 69-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 72-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 68-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 62-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 65-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 59-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 56-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 57-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 64-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 58-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 60-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 63-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 54-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.81324786 0.86695157 0.83269231 0.85569801 0.72264957        nan\n",
      "        nan 0.87820513]\n",
      "  warnings.warn(\n",
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8782051282051282\n",
      "Best estimator parameters:  {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy 0.813 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.867 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.833 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.856 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.723 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.878 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ts_dataset.iloc[:, 0:len(ts_dataset.columns)-1].copy()\n",
    "y = pd.DataFrame(ts_dataset.iloc[:, -1])\n",
    "# split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X, y)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "id        \n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "5        0\n",
       "..     ...\n",
       "114      1\n",
       "115      1\n",
       "116      0\n",
       "117      1\n",
       "118      1\n",
       "\n",
       "[118 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        13\n",
       "1        11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  1.0\n",
      "Mean accuracy on training data:  1.0\n",
      "Log Marginal Likelihood: -66.332\n",
      "Log Marginal Likelihood: -36.872\n",
      "Log-loss: 0.559 (initial) 0.189 (optimized)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method GaussianProcessClassifier.predict_proba of GaussianProcessClassifier(kernel=1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5),\n",
       "                          n_jobs=-1, random_state=18)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_kernel = 1*DotProduct()\n",
    "best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "\n",
    "model_ini = GaussianProcessClassifier(kernel=best_kernel, random_state=10, n_jobs=-1, optimizer=None)\n",
    "model_ini.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model_ini.score(X_train, y_train))\n",
    "\n",
    "model_opt = GaussianProcessClassifier(kernel=best_kernel, random_state=18, n_jobs=-1)\n",
    "model_opt.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model_opt.score(X_train, y_train))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Log Marginal Likelihood: %.3f\"\n",
    "    % model_ini.log_marginal_likelihood(model_ini.kernel_.theta)\n",
    ")\n",
    "print(\n",
    "    \"Log Marginal Likelihood: %.3f\"\n",
    "    % model_opt.log_marginal_likelihood(model_opt.kernel_.theta)\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Log-loss: %.3f (initial) %.3f (optimized)\"\n",
    "    % (\n",
    "        log_loss(y_train, model_ini.predict_proba(X_train)[:, 1]),\n",
    "        log_loss(y_train, model_opt.predict_proba(X_train)[:, 1]),\n",
    "    )\n",
    ")\n",
    "\n",
    "model_opt.predict_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'GPC-DotProduct-Train'),\n",
       " Text(0.5, 0, 'Predicted probability(positive class)'),\n",
       " Text(0, 0.5, 'Count')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.hist(\n",
    "    model_opt.predict_proba(X_train)[:,1],\n",
    "    range=(0, 1),\n",
    "    bins=10,\n",
    "    label=\"GP\",\n",
    "    color=colors(1),\n",
    "    )\n",
    "ax.set(title=\"GPC-DotProduct-Train\", xlabel=\"Predicted probability(positive class)\", ylabel=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        11\n",
       "1         6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        24\n",
       "1         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2106046 , 0.84047319, 0.85173971, 0.1444538 , 0.81162486,\n",
       "       0.19780321, 0.25079181, 0.20313554, 0.95650529, 0.96846936,\n",
       "       0.95593061, 0.92634373, 0.74389922, 0.74282412, 0.84529774,\n",
       "       0.72905025, 0.8075667 , 0.73843693, 0.15658514, 0.21835854,\n",
       "       0.95920903, 0.22004996, 0.95823759, 0.81617219, 0.7962108 ,\n",
       "       0.93518495, 0.93215651, 0.30517105, 0.71734829, 0.85278873,\n",
       "       0.93615969, 0.80153155, 0.80547532, 0.74231205, 0.69406327,\n",
       "       0.09633175, 0.17948264, 0.82984861, 0.83789983, 0.92028683,\n",
       "       0.93042304, 0.76940379, 0.24757791, 0.19201591, 0.75919633,\n",
       "       0.19194801, 0.90401086, 0.92347138, 0.90456991, 0.75507705,\n",
       "       0.78166977, 0.9528812 , 0.71305654, 0.84248292, 0.76890422,\n",
       "       0.85726648, 0.88614933, 0.8242286 , 0.75170263, 0.75113801,\n",
       "       0.75843072, 0.20602955, 0.81633134, 0.82935454, 0.92281863,\n",
       "       0.74888475, 0.85055077, 0.93370087, 0.19511675, 0.88011106,\n",
       "       0.72856978, 0.75051339, 0.72623344, 0.29068142, 0.91331638,\n",
       "       0.63178673, 0.66339779, 0.8786773 , 0.26290279, 0.80428879,\n",
       "       0.22934656, 0.84476745, 0.26009462, 0.91881861, 0.29195558,\n",
       "       0.18832603, 0.73878625])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt.predict_proba(X_train)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  0.7692307692307693\n",
      "Prediction on test data:  [1 1 1 1]\n",
      "Prediction accuracy on test data:  0.5\n"
     ]
    }
   ],
   "source": [
    "#best_kernel = 1*DotProduct()\n",
    "#best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "#best_kernel = 1*RBF()\n",
    "best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=20, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>Age__standard_deviation</th>\n",
       "      <th>Age__variance</th>\n",
       "      <th>Total_MilkProduction__sum_values</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>milking_times__mean.1</th>\n",
       "      <th>milking_times__root_mean_square.1</th>\n",
       "      <th>milking_times__length.1</th>\n",
       "      <th>milking_times__maximum.1</th>\n",
       "      <th>milking_times__absolute_maximum.1</th>\n",
       "      <th>milking_times__median.1</th>\n",
       "      <th>milking_times__standard_deviation.1</th>\n",
       "      <th>milking_times__variance.1</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524434</td>\n",
       "      <td>1.085858</td>\n",
       "      <td>1.079378</td>\n",
       "      <td>1.101637</td>\n",
       "      <td>0.514914</td>\n",
       "      <td>1.085858</td>\n",
       "      <td>0.047985</td>\n",
       "      <td>-0.117160</td>\n",
       "      <td>0.251880</td>\n",
       "      <td>0.089892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007509</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>-1.393442</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.402734</td>\n",
       "      <td>-0.443021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008898</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>0.470140</td>\n",
       "      <td>0.425319</td>\n",
       "      <td>1.514386</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>0.292065</td>\n",
       "      <td>0.279305</td>\n",
       "      <td>0.312188</td>\n",
       "      <td>0.153706</td>\n",
       "      <td>...</td>\n",
       "      <td>2.806171</td>\n",
       "      <td>2.782333</td>\n",
       "      <td>-1.826475</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1.469615</td>\n",
       "      <td>-1.431467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.266430</td>\n",
       "      <td>-0.032117</td>\n",
       "      <td>-0.142078</td>\n",
       "      <td>-0.206394</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>-0.032117</td>\n",
       "      <td>-1.373574</td>\n",
       "      <td>-1.252952</td>\n",
       "      <td>-1.441097</td>\n",
       "      <td>-1.215417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.956602</td>\n",
       "      <td>-1.281174</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.528312</td>\n",
       "      <td>0.501252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.248974</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>0.117640</td>\n",
       "      <td>0.055729</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>0.743236</td>\n",
       "      <td>0.666859</td>\n",
       "      <td>0.553087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148210</td>\n",
       "      <td>0.164350</td>\n",
       "      <td>0.130193</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.539564</td>\n",
       "      <td>0.513130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.342294</td>\n",
       "      <td>1.553847</td>\n",
       "      <td>1.710117</td>\n",
       "      <td>1.851932</td>\n",
       "      <td>1.268918</td>\n",
       "      <td>1.553847</td>\n",
       "      <td>-0.452687</td>\n",
       "      <td>-0.203410</td>\n",
       "      <td>-0.745908</td>\n",
       "      <td>-0.793001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848795</td>\n",
       "      <td>-0.811337</td>\n",
       "      <td>0.402843</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.941142</td>\n",
       "      <td>0.944306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.014733</td>\n",
       "      <td>-1.124092</td>\n",
       "      <td>-1.009327</td>\n",
       "      <td>-1.019051</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>-1.124092</td>\n",
       "      <td>-1.703311</td>\n",
       "      <td>-1.455537</td>\n",
       "      <td>-1.927615</td>\n",
       "      <td>-1.416896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686537</td>\n",
       "      <td>-0.644701</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.071787</td>\n",
       "      <td>1.087634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.265372</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>0.529172</td>\n",
       "      <td>0.488770</td>\n",
       "      <td>-1.340405</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>-0.854216</td>\n",
       "      <td>-0.823393</td>\n",
       "      <td>-0.836862</td>\n",
       "      <td>-0.857266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.469579</td>\n",
       "      <td>-0.449131</td>\n",
       "      <td>-0.463223</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.610262</td>\n",
       "      <td>0.588011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.137415</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>0.510070</td>\n",
       "      <td>0.468189</td>\n",
       "      <td>-0.916507</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>1.163018</td>\n",
       "      <td>0.932482</td>\n",
       "      <td>1.401886</td>\n",
       "      <td>1.511931</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057144</td>\n",
       "      <td>1.070814</td>\n",
       "      <td>-1.617978</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.412278</td>\n",
       "      <td>0.379418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.777087</td>\n",
       "      <td>-0.812099</td>\n",
       "      <td>-0.787309</td>\n",
       "      <td>-0.820187</td>\n",
       "      <td>-1.244746</td>\n",
       "      <td>-0.812099</td>\n",
       "      <td>-0.493014</td>\n",
       "      <td>-0.482371</td>\n",
       "      <td>-0.466806</td>\n",
       "      <td>-0.578883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343693</td>\n",
       "      <td>-0.365859</td>\n",
       "      <td>0.787762</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.452701</td>\n",
       "      <td>-0.491545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.866793</td>\n",
       "      <td>1.501849</td>\n",
       "      <td>1.534682</td>\n",
       "      <td>1.638126</td>\n",
       "      <td>1.145617</td>\n",
       "      <td>1.501849</td>\n",
       "      <td>-0.450061</td>\n",
       "      <td>-0.736638</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>-0.274731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230736</td>\n",
       "      <td>-0.277878</td>\n",
       "      <td>-0.896256</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.146235</td>\n",
       "      <td>-1.142418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.493985</td>\n",
       "      <td>-1.774078</td>\n",
       "      <td>-1.728078</td>\n",
       "      <td>-1.619521</td>\n",
       "      <td>-0.835757</td>\n",
       "      <td>-1.774078</td>\n",
       "      <td>-0.253874</td>\n",
       "      <td>-0.261022</td>\n",
       "      <td>-0.216664</td>\n",
       "      <td>-0.365304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.878951</td>\n",
       "      <td>-0.900088</td>\n",
       "      <td>0.948144</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.434538</td>\n",
       "      <td>-0.473932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.468623</td>\n",
       "      <td>-1.566082</td>\n",
       "      <td>-1.462721</td>\n",
       "      <td>-1.405541</td>\n",
       "      <td>-1.972024</td>\n",
       "      <td>-1.566082</td>\n",
       "      <td>0.337339</td>\n",
       "      <td>0.164147</td>\n",
       "      <td>0.540952</td>\n",
       "      <td>0.406592</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.540621</td>\n",
       "      <td>-1.578647</td>\n",
       "      <td>0.675494</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.903357</td>\n",
       "      <td>-0.919286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.077756</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>0.143323</td>\n",
       "      <td>0.082119</td>\n",
       "      <td>-0.295360</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>1.072410</td>\n",
       "      <td>0.714301</td>\n",
       "      <td>1.451905</td>\n",
       "      <td>1.583611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003606</td>\n",
       "      <td>0.026885</td>\n",
       "      <td>1.317025</td>\n",
       "      <td>2.262742</td>\n",
       "      <td>2.262742</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.894960</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.305019</td>\n",
       "      <td>-1.514084</td>\n",
       "      <td>-1.611870</td>\n",
       "      <td>-1.526924</td>\n",
       "      <td>-0.295093</td>\n",
       "      <td>-1.514084</td>\n",
       "      <td>-0.052647</td>\n",
       "      <td>0.109351</td>\n",
       "      <td>-0.241790</td>\n",
       "      <td>-0.387683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144356</td>\n",
       "      <td>-0.088775</td>\n",
       "      <td>0.948144</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.478852</td>\n",
       "      <td>1.543825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.132805</td>\n",
       "      <td>0.045881</td>\n",
       "      <td>0.047668</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.371351</td>\n",
       "      <td>0.045881</td>\n",
       "      <td>-0.749968</td>\n",
       "      <td>-0.588997</td>\n",
       "      <td>-0.901028</td>\n",
       "      <td>-0.900974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397711</td>\n",
       "      <td>-0.349167</td>\n",
       "      <td>0.146231</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.276423</td>\n",
       "      <td>1.315147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.270390</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>-0.012724</td>\n",
       "      <td>-0.076922</td>\n",
       "      <td>1.462701</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>2.640457</td>\n",
       "      <td>3.055026</td>\n",
       "      <td>1.926947</td>\n",
       "      <td>2.305212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532720</td>\n",
       "      <td>0.485411</td>\n",
       "      <td>0.675494</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.305924</td>\n",
       "      <td>-1.286302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.772878</td>\n",
       "      <td>0.513871</td>\n",
       "      <td>0.611917</td>\n",
       "      <td>0.578460</td>\n",
       "      <td>0.535894</td>\n",
       "      <td>0.513871</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>-0.076369</td>\n",
       "      <td>0.342403</td>\n",
       "      <td>0.186123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946518</td>\n",
       "      <td>-1.014034</td>\n",
       "      <td>0.466997</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.638476</td>\n",
       "      <td>-1.578751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age__sum_values  Age__length  Age__standard_deviation  Age__variance  \\\n",
       "id                                                                         \n",
       "1          0.524434     1.085858                 1.079378       1.101637   \n",
       "2         -0.008898     0.565870                 0.470140       0.425319   \n",
       "3         -0.266430    -0.032117                -0.142078      -0.206394   \n",
       "4         -0.248974     0.123880                 0.117640       0.055729   \n",
       "5          1.342294     1.553847                 1.710117       1.851932   \n",
       "6         -1.014733    -1.124092                -1.009327      -1.019051   \n",
       "7          0.265372     0.617868                 0.529172       0.488770   \n",
       "8          0.137415     0.565870                 0.510070       0.468189   \n",
       "9         -0.777087    -0.812099                -0.787309      -0.820187   \n",
       "10         2.866793     1.501849                 1.534682       1.638126   \n",
       "11        -1.493985    -1.774078                -1.728078      -1.619521   \n",
       "12        -0.468623    -1.566082                -1.462721      -1.405541   \n",
       "13         0.077756     0.123880                 0.143323       0.082119   \n",
       "14        -1.305019    -1.514084                -1.611870      -1.526924   \n",
       "15        -0.132805     0.045881                 0.047668      -0.015741   \n",
       "16        -0.270390     0.123880                -0.012724      -0.076922   \n",
       "17         0.772878     0.513871                 0.611917       0.578460   \n",
       "\n",
       "    Total_MilkProduction__sum_values  Total_MilkProduction__length  \\\n",
       "id                                                                   \n",
       "1                           0.514914                      1.085858   \n",
       "2                           1.514386                      0.565870   \n",
       "3                           0.080839                     -0.032117   \n",
       "4                          -0.001418                      0.123880   \n",
       "5                           1.268918                      1.553847   \n",
       "6                           0.006688                     -1.124092   \n",
       "7                          -1.340405                      0.617868   \n",
       "8                          -0.916507                      0.565870   \n",
       "9                          -1.244746                     -0.812099   \n",
       "10                          1.145617                      1.501849   \n",
       "11                         -0.835757                     -1.774078   \n",
       "12                         -1.972024                     -1.566082   \n",
       "13                         -0.295360                      0.123880   \n",
       "14                         -0.295093                     -1.514084   \n",
       "15                          0.371351                      0.045881   \n",
       "16                          1.462701                      0.123880   \n",
       "17                          0.535894                      0.513871   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  Total_timeDelta_Seconds__mean  \\\n",
       "id                                                                             \n",
       "1                                    0.047985                      -0.117160   \n",
       "2                                    0.292065                       0.279305   \n",
       "3                                   -1.373574                      -1.252952   \n",
       "4                                    0.716305                       0.743236   \n",
       "5                                   -0.452687                      -0.203410   \n",
       "6                                   -1.703311                      -1.455537   \n",
       "7                                   -0.854216                      -0.823393   \n",
       "8                                    1.163018                       0.932482   \n",
       "9                                   -0.493014                      -0.482371   \n",
       "10                                  -0.450061                      -0.736638   \n",
       "11                                  -0.253874                      -0.261022   \n",
       "12                                   0.337339                       0.164147   \n",
       "13                                   1.072410                       0.714301   \n",
       "14                                  -0.052647                       0.109351   \n",
       "15                                  -0.749968                      -0.588997   \n",
       "16                                   2.640457                       3.055026   \n",
       "17                                   0.113773                      -0.076369   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "id                                                \n",
       "1                                      0.251880   \n",
       "2                                      0.312188   \n",
       "3                                     -1.441097   \n",
       "4                                      0.666859   \n",
       "5                                     -0.745908   \n",
       "6                                     -1.927615   \n",
       "7                                     -0.836862   \n",
       "8                                      1.401886   \n",
       "9                                     -0.466806   \n",
       "10                                    -0.117250   \n",
       "11                                    -0.216664   \n",
       "12                                     0.540952   \n",
       "13                                     1.451905   \n",
       "14                                    -0.241790   \n",
       "15                                    -0.901028   \n",
       "16                                     1.926947   \n",
       "17                                     0.342403   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  ...  milking_times__mean.1  \\\n",
       "id                                     ...                          \n",
       "1                            0.089892  ...               1.007509   \n",
       "2                            0.153706  ...               2.806171   \n",
       "3                           -1.215417  ...               0.939348   \n",
       "4                            0.553087  ...               0.148210   \n",
       "5                           -0.793001  ...              -0.848795   \n",
       "6                           -1.416896  ...              -0.686537   \n",
       "7                           -0.857266  ...              -0.469579   \n",
       "8                            1.511931  ...               1.057144   \n",
       "9                           -0.578883  ...              -0.343693   \n",
       "10                          -0.274731  ...              -0.230736   \n",
       "11                          -0.365304  ...              -0.878951   \n",
       "12                           0.406592  ...              -1.540621   \n",
       "13                           1.583611  ...              -0.003606   \n",
       "14                          -0.387683  ...              -0.144356   \n",
       "15                          -0.900974  ...              -0.397711   \n",
       "16                           2.305212  ...               0.532720   \n",
       "17                           0.186123  ...              -0.946518   \n",
       "\n",
       "    milking_times__root_mean_square.1  milking_times__length.1  \\\n",
       "id                                                               \n",
       "1                            0.993223                -1.393442   \n",
       "2                            2.782333                -1.826475   \n",
       "3                            0.956602                -1.281174   \n",
       "4                            0.164350                 0.130193   \n",
       "5                           -0.811337                 0.402843   \n",
       "6                           -0.644701                 0.980221   \n",
       "7                           -0.449131                -0.463223   \n",
       "8                            1.070814                -1.617978   \n",
       "9                           -0.365859                 0.787762   \n",
       "10                          -0.277878                -0.896256   \n",
       "11                          -0.900088                 0.948144   \n",
       "12                          -1.578647                 0.675494   \n",
       "13                           0.026885                 1.317025   \n",
       "14                          -0.088775                 0.948144   \n",
       "15                          -0.349167                 0.146231   \n",
       "16                           0.485411                 0.675494   \n",
       "17                          -1.014034                 0.466997   \n",
       "\n",
       "    milking_times__maximum.1  milking_times__absolute_maximum.1  \\\n",
       "id                                                                \n",
       "1                  -0.141421                          -0.141421   \n",
       "2                   1.060660                           1.060660   \n",
       "3                   1.060660                           1.060660   \n",
       "4                  -0.141421                          -0.141421   \n",
       "5                  -1.343503                          -1.343503   \n",
       "6                  -0.141421                          -0.141421   \n",
       "7                  -0.141421                          -0.141421   \n",
       "8                   1.060660                           1.060660   \n",
       "9                  -0.141421                          -0.141421   \n",
       "10                 -1.343503                          -1.343503   \n",
       "11                 -1.343503                          -1.343503   \n",
       "12                 -0.141421                          -0.141421   \n",
       "13                  2.262742                           2.262742   \n",
       "14                  1.060660                           1.060660   \n",
       "15                 -0.141421                          -0.141421   \n",
       "16                 -0.141421                          -0.141421   \n",
       "17                 -1.343503                          -1.343503   \n",
       "\n",
       "    milking_times__median.1  milking_times__standard_deviation.1  \\\n",
       "id                                                                 \n",
       "1                     -0.25                            -0.402734   \n",
       "2                      4.00                            -1.469615   \n",
       "3                     -0.25                             0.528312   \n",
       "4                     -0.25                             0.539564   \n",
       "5                     -0.25                             0.941142   \n",
       "6                     -0.25                             1.071787   \n",
       "7                     -0.25                             0.610262   \n",
       "8                     -0.25                             0.412278   \n",
       "9                     -0.25                            -0.452701   \n",
       "10                    -0.25                            -1.146235   \n",
       "11                    -0.25                            -0.434538   \n",
       "12                    -0.25                            -0.903357   \n",
       "13                    -0.25                             0.894960   \n",
       "14                    -0.25                             1.478852   \n",
       "15                    -0.25                             1.276423   \n",
       "16                    -0.25                            -1.305924   \n",
       "17                    -0.25                            -1.638476   \n",
       "\n",
       "    milking_times__variance.1  BreedName_1  BreedName_2  \n",
       "id                                                       \n",
       "1                   -0.443021          0.0          1.0  \n",
       "2                   -1.431467          0.0          1.0  \n",
       "3                    0.501252          1.0          0.0  \n",
       "4                    0.513130          1.0          0.0  \n",
       "5                    0.944306          1.0          0.0  \n",
       "6                    1.087634          1.0          0.0  \n",
       "7                    0.588011          1.0          0.0  \n",
       "8                    0.379418          0.0          1.0  \n",
       "9                   -0.491545          1.0          0.0  \n",
       "10                  -1.142418          0.0          1.0  \n",
       "11                  -0.473932          0.0          1.0  \n",
       "12                  -0.919286          1.0          0.0  \n",
       "13                   0.894000          0.0          1.0  \n",
       "14                   1.543825          0.0          1.0  \n",
       "15                   1.315147          1.0          0.0  \n",
       "16                  -1.286302          0.0          1.0  \n",
       "17                  -1.578751          0.0          1.0  \n",
       "\n",
       "[17 rows x 58 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        12\n",
       "0         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "id       \n",
       "8       0\n",
       "4       1\n",
       "2       1\n",
       "12      0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84510538, 0.15489462],\n",
       "       [0.21143657, 0.78856343],\n",
       "       [0.49640214, 0.50359786],\n",
       "       [0.89765126, 0.10234874],\n",
       "       [0.66126536, 0.33873464],\n",
       "       [0.93029955, 0.06970045],\n",
       "       [0.58285054, 0.41714946],\n",
       "       [0.81066071, 0.18933929],\n",
       "       [0.74715522, 0.25284478],\n",
       "       [0.55208842, 0.44791158],\n",
       "       [0.81411315, 0.18588685],\n",
       "       [0.89935271, 0.10064729],\n",
       "       [0.18900759, 0.81099241],\n",
       "       [0.94346549, 0.05653451],\n",
       "       [0.60316412, 0.39683588],\n",
       "       [0.86062169, 0.13937831],\n",
       "       [0.51587677, 0.48412323],\n",
       "       [0.7234912 , 0.2765088 ],\n",
       "       [0.60559614, 0.39440386],\n",
       "       [0.82852317, 0.17147683],\n",
       "       [0.94054889, 0.05945111],\n",
       "       [0.93733989, 0.06266011],\n",
       "       [0.89697543, 0.10302457],\n",
       "       [0.93164914, 0.06835086],\n",
       "       [0.59767041, 0.40232959],\n",
       "       [0.94466663, 0.05533337],\n",
       "       [0.62988908, 0.37011092],\n",
       "       [0.2784378 , 0.7215622 ],\n",
       "       [0.79571289, 0.20428711]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['46', '95', '57', '85', '98', '42', '81', '108', '49', '3', '54', '53',\n",
       "       '93', '44', '80', '2', '11', '36', '48', '27', '69', '82', '38', '20',\n",
       "       '15', '40', '39', '64', '103'],\n",
       "      dtype='object', name='id')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "cow_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#fd625e'\n",
    "color_blue = '#01b8aa'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Bad learner, test set'\n",
    "title1 = 'Good learner, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'good&bad_learner'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'GPC-Matern-Test'),\n",
       " Text(0.5, 0, 'Predicted probability(positive class)'),\n",
       " Text(0, 0.5, 'Count')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.hist(\n",
    "    model.predict_proba(X_test)[:,1],\n",
    "    range=(0, 1),\n",
    "    bins=10,\n",
    "    label=\"GP\",\n",
    "    color=colors(1),\n",
    "    )\n",
    "ax.set(title=\"GPC-Matern-Test\", xlabel=\"Predicted probability(positive class)\", ylabel=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__quantile__q_0.7</th>\n",
       "      <th>Total_timeDelta_Seconds__quantile__q_0.6</th>\n",
       "      <th>Total_timeDelta_Seconds__mean_abs_change</th>\n",
       "      <th>Total_timeDelta_Seconds__quantile__q_0.8</th>\n",
       "      <th>Total_timeDelta_Seconds__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.0</th>\n",
       "      <th>Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0</th>\n",
       "      <th>Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>milking_times__large_standard_deviation__r_0.2</th>\n",
       "      <th>Age__absolute_sum_of_changes</th>\n",
       "      <th>milking_times__number_peaks__n_3</th>\n",
       "      <th>milking_times__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"</th>\n",
       "      <th>DaysInMilk__fft_coefficient__attr_\"real\"__coeff_68</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.040361</td>\n",
       "      <td>-1.052863</td>\n",
       "      <td>-1.044957</td>\n",
       "      <td>-1.026876</td>\n",
       "      <td>-1.032387</td>\n",
       "      <td>-1.105493</td>\n",
       "      <td>-1.032387</td>\n",
       "      <td>-0.617057</td>\n",
       "      <td>-0.604327</td>\n",
       "      <td>-0.606794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>0.141238</td>\n",
       "      <td>-1.455100</td>\n",
       "      <td>0.638454</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.671826</td>\n",
       "      <td>2.183100</td>\n",
       "      <td>1.493171</td>\n",
       "      <td>1.562288</td>\n",
       "      <td>2.132024</td>\n",
       "      <td>1.807215</td>\n",
       "      <td>2.132024</td>\n",
       "      <td>1.331007</td>\n",
       "      <td>2.399062</td>\n",
       "      <td>3.831282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>-1.538254</td>\n",
       "      <td>-1.455100</td>\n",
       "      <td>1.640353</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.343801</td>\n",
       "      <td>-0.478895</td>\n",
       "      <td>-0.609450</td>\n",
       "      <td>-0.648323</td>\n",
       "      <td>-0.377595</td>\n",
       "      <td>-0.563320</td>\n",
       "      <td>-0.377595</td>\n",
       "      <td>-0.520889</td>\n",
       "      <td>-0.494788</td>\n",
       "      <td>-0.318304</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>1.238049</td>\n",
       "      <td>-1.063017</td>\n",
       "      <td>-0.792830</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.636363</td>\n",
       "      <td>3.097751</td>\n",
       "      <td>3.038055</td>\n",
       "      <td>2.773486</td>\n",
       "      <td>3.344164</td>\n",
       "      <td>3.524035</td>\n",
       "      <td>3.344164</td>\n",
       "      <td>4.127197</td>\n",
       "      <td>1.691970</td>\n",
       "      <td>1.799513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>-1.538254</td>\n",
       "      <td>-1.259059</td>\n",
       "      <td>0.638454</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.328595</td>\n",
       "      <td>-0.216554</td>\n",
       "      <td>-0.058725</td>\n",
       "      <td>-0.097482</td>\n",
       "      <td>-0.275922</td>\n",
       "      <td>-0.030931</td>\n",
       "      <td>-0.275922</td>\n",
       "      <td>-0.255325</td>\n",
       "      <td>-0.383424</td>\n",
       "      <td>-0.447120</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>-0.441443</td>\n",
       "      <td>-1.651141</td>\n",
       "      <td>0.352197</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.591009</td>\n",
       "      <td>-0.654956</td>\n",
       "      <td>-0.670955</td>\n",
       "      <td>-0.708766</td>\n",
       "      <td>-0.588152</td>\n",
       "      <td>-0.632789</td>\n",
       "      <td>-0.588152</td>\n",
       "      <td>-0.507241</td>\n",
       "      <td>-0.480969</td>\n",
       "      <td>-0.463305</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>1.203774</td>\n",
       "      <td>-0.278852</td>\n",
       "      <td>-0.300620</td>\n",
       "      <td>-0.560212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.938013</td>\n",
       "      <td>-0.998320</td>\n",
       "      <td>-1.044877</td>\n",
       "      <td>-1.035654</td>\n",
       "      <td>-0.932922</td>\n",
       "      <td>-1.005204</td>\n",
       "      <td>-0.932922</td>\n",
       "      <td>-0.607456</td>\n",
       "      <td>-0.580659</td>\n",
       "      <td>-0.575167</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>0.621093</td>\n",
       "      <td>0.897396</td>\n",
       "      <td>0.693267</td>\n",
       "      <td>-0.599109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.738820</td>\n",
       "      <td>-0.847421</td>\n",
       "      <td>-0.930653</td>\n",
       "      <td>-0.919554</td>\n",
       "      <td>-0.831356</td>\n",
       "      <td>-0.871078</td>\n",
       "      <td>-0.831356</td>\n",
       "      <td>-0.598774</td>\n",
       "      <td>-0.592489</td>\n",
       "      <td>-0.502985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>1.375150</td>\n",
       "      <td>0.309272</td>\n",
       "      <td>-1.219308</td>\n",
       "      <td>-0.747028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.739600</td>\n",
       "      <td>-0.681753</td>\n",
       "      <td>-0.666603</td>\n",
       "      <td>-0.588145</td>\n",
       "      <td>-0.771759</td>\n",
       "      <td>-0.694471</td>\n",
       "      <td>-0.771759</td>\n",
       "      <td>-0.549616</td>\n",
       "      <td>-0.471381</td>\n",
       "      <td>-0.559385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>1.409426</td>\n",
       "      <td>0.309272</td>\n",
       "      <td>-0.976547</td>\n",
       "      <td>-0.733278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.913186</td>\n",
       "      <td>-0.940307</td>\n",
       "      <td>-0.966793</td>\n",
       "      <td>-0.952934</td>\n",
       "      <td>-0.900540</td>\n",
       "      <td>-0.966230</td>\n",
       "      <td>-0.900540</td>\n",
       "      <td>-0.604145</td>\n",
       "      <td>-0.585625</td>\n",
       "      <td>-0.576851</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>0.895295</td>\n",
       "      <td>0.113231</td>\n",
       "      <td>-0.155242</td>\n",
       "      <td>-0.934079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total_timeDelta_Seconds__root_mean_square  Total_timeDelta_Seconds__mean  \\\n",
       "id                                                                              \n",
       "1                                    -1.040361                      -1.052863   \n",
       "2                                     2.671826                       2.183100   \n",
       "3                                    -0.343801                      -0.478895   \n",
       "4                                     2.636363                       3.097751   \n",
       "5                                    -0.328595                      -0.216554   \n",
       "..                                         ...                            ...   \n",
       "112                                  -0.591009                      -0.654956   \n",
       "113                                  -0.938013                      -0.998320   \n",
       "114                                  -0.738820                      -0.847421   \n",
       "115                                  -0.739600                      -0.681753   \n",
       "116                                  -0.913186                      -0.940307   \n",
       "\n",
       "     Total_timeDelta_Seconds__quantile__q_0.7  \\\n",
       "id                                              \n",
       "1                                   -1.044957   \n",
       "2                                    1.493171   \n",
       "3                                   -0.609450   \n",
       "4                                    3.038055   \n",
       "5                                   -0.058725   \n",
       "..                                        ...   \n",
       "112                                 -0.670955   \n",
       "113                                 -1.044877   \n",
       "114                                 -0.930653   \n",
       "115                                 -0.666603   \n",
       "116                                 -0.966793   \n",
       "\n",
       "     Total_timeDelta_Seconds__quantile__q_0.6  \\\n",
       "id                                              \n",
       "1                                   -1.026876   \n",
       "2                                    1.562288   \n",
       "3                                   -0.648323   \n",
       "4                                    2.773486   \n",
       "5                                   -0.097482   \n",
       "..                                        ...   \n",
       "112                                 -0.708766   \n",
       "113                                 -1.035654   \n",
       "114                                 -0.919554   \n",
       "115                                 -0.588145   \n",
       "116                                 -0.952934   \n",
       "\n",
       "     Total_timeDelta_Seconds__mean_abs_change  \\\n",
       "id                                              \n",
       "1                                   -1.032387   \n",
       "2                                    2.132024   \n",
       "3                                   -0.377595   \n",
       "4                                    3.344164   \n",
       "5                                   -0.275922   \n",
       "..                                        ...   \n",
       "112                                 -0.588152   \n",
       "113                                 -0.932922   \n",
       "114                                 -0.831356   \n",
       "115                                 -0.771759   \n",
       "116                                 -0.900540   \n",
       "\n",
       "     Total_timeDelta_Seconds__quantile__q_0.8  \\\n",
       "id                                              \n",
       "1                                   -1.105493   \n",
       "2                                    1.807215   \n",
       "3                                   -0.563320   \n",
       "4                                    3.524035   \n",
       "5                                   -0.030931   \n",
       "..                                        ...   \n",
       "112                                 -0.632789   \n",
       "113                                 -1.005204   \n",
       "114                                 -0.871078   \n",
       "115                                 -0.694471   \n",
       "116                                 -0.966230   \n",
       "\n",
       "     Total_timeDelta_Seconds__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.0  \\\n",
       "id                                                                                         \n",
       "1                                            -1.032387                                     \n",
       "2                                             2.132024                                     \n",
       "3                                            -0.377595                                     \n",
       "4                                             3.344164                                     \n",
       "5                                            -0.275922                                     \n",
       "..                                                 ...                                     \n",
       "112                                          -0.588152                                     \n",
       "113                                          -0.932922                                     \n",
       "114                                          -0.831356                                     \n",
       "115                                          -0.771759                                     \n",
       "116                                          -0.900540                                     \n",
       "\n",
       "     Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0  \\\n",
       "id                                                                                        \n",
       "1                                            -0.617057                                    \n",
       "2                                             1.331007                                    \n",
       "3                                            -0.520889                                    \n",
       "4                                             4.127197                                    \n",
       "5                                            -0.255325                                    \n",
       "..                                                 ...                                    \n",
       "112                                          -0.507241                                    \n",
       "113                                          -0.607456                                    \n",
       "114                                          -0.598774                                    \n",
       "115                                          -0.549616                                    \n",
       "116                                          -0.604145                                    \n",
       "\n",
       "     Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2  \\\n",
       "id                                                                                        \n",
       "1                                            -0.604327                                    \n",
       "2                                             2.399062                                    \n",
       "3                                            -0.494788                                    \n",
       "4                                             1.691970                                    \n",
       "5                                            -0.383424                                    \n",
       "..                                                 ...                                    \n",
       "112                                          -0.480969                                    \n",
       "113                                          -0.580659                                    \n",
       "114                                          -0.592489                                    \n",
       "115                                          -0.471381                                    \n",
       "116                                          -0.585625                                    \n",
       "\n",
       "     Total_timeDelta_Seconds__variance  ...  \\\n",
       "id                                      ...   \n",
       "1                            -0.606794  ...   \n",
       "2                             3.831282  ...   \n",
       "3                            -0.318304  ...   \n",
       "4                             1.799513  ...   \n",
       "5                            -0.447120  ...   \n",
       "..                                 ...  ...   \n",
       "112                          -0.463305  ...   \n",
       "113                          -0.575167  ...   \n",
       "114                          -0.502985  ...   \n",
       "115                          -0.559385  ...   \n",
       "116                          -0.576851  ...   \n",
       "\n",
       "     milking_times__large_standard_deviation__r_0.2  \\\n",
       "id                                                    \n",
       "1                                          0.855186   \n",
       "2                                          0.855186   \n",
       "3                                         -1.169336   \n",
       "4                                          0.855186   \n",
       "5                                         -1.169336   \n",
       "..                                              ...   \n",
       "112                                       -1.169336   \n",
       "113                                       -1.169336   \n",
       "114                                        0.855186   \n",
       "115                                        0.855186   \n",
       "116                                       -1.169336   \n",
       "\n",
       "     Age__absolute_sum_of_changes  milking_times__number_peaks__n_3  \\\n",
       "id                                                                    \n",
       "1                        0.141238                         -1.455100   \n",
       "2                       -1.538254                         -1.455100   \n",
       "3                        1.238049                         -1.063017   \n",
       "4                       -1.538254                         -1.259059   \n",
       "5                       -0.441443                         -1.651141   \n",
       "..                            ...                               ...   \n",
       "112                      1.203774                         -0.278852   \n",
       "113                      0.621093                          0.897396   \n",
       "114                      1.375150                          0.309272   \n",
       "115                      1.409426                          0.309272   \n",
       "116                      0.895295                          0.113231   \n",
       "\n",
       "     milking_times__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"  \\\n",
       "id                                                                             \n",
       "1                                             0.638454                         \n",
       "2                                             1.640353                         \n",
       "3                                            -0.792830                         \n",
       "4                                             0.638454                         \n",
       "5                                             0.352197                         \n",
       "..                                                 ...                         \n",
       "112                                          -0.300620                         \n",
       "113                                           0.693267                         \n",
       "114                                          -1.219308                         \n",
       "115                                          -0.976547                         \n",
       "116                                          -0.155242                         \n",
       "\n",
       "     DaysInMilk__fft_coefficient__attr_\"real\"__coeff_68  BreedName_1  \\\n",
       "id                                                                     \n",
       "1                                             0.079254           0.0   \n",
       "2                                             0.079254           0.0   \n",
       "3                                             0.079254           0.0   \n",
       "4                                             0.079254           0.0   \n",
       "5                                             0.079254           0.0   \n",
       "..                                                 ...           ...   \n",
       "112                                          -0.560212           0.0   \n",
       "113                                          -0.599109           1.0   \n",
       "114                                          -0.747028           0.0   \n",
       "115                                          -0.733278           1.0   \n",
       "116                                          -0.934079           1.0   \n",
       "\n",
       "     BreedName_2  BreedName_4  BreedName_99  label  \n",
       "id                                                  \n",
       "1            0.0          1.0           0.0      0  \n",
       "2            0.0          0.0           1.0      0  \n",
       "3            1.0          0.0           0.0      0  \n",
       "4            0.0          0.0           1.0      0  \n",
       "5            1.0          0.0           0.0      0  \n",
       "..           ...          ...           ...    ...  \n",
       "112          1.0          0.0           0.0      0  \n",
       "113          0.0          0.0           0.0      1  \n",
       "114          1.0          0.0           0.0      1  \n",
       "115          0.0          0.0           0.0      0  \n",
       "116          0.0          0.0           0.0      1  \n",
       "\n",
       "[116 rows x 991 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prediction, std_prediction = model.predict(X, return_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(\n",
    "    X_train, y_train.values.ravel()\n",
    "    pred\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
