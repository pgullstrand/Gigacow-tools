{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct, Matern, RationalQuadratic, WhiteKernel, ExpSineSquared\n",
    "grid = dict()\n",
    "grid['kernel'] = [1*RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)), \n",
    "                  1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),\n",
    "                  1*Matern()+1*WhiteKernel(noise_level=0.5),\n",
    "                  1*ExpSineSquared(),\n",
    "                  1.0 * ExpSineSquared(length_scale=1.0, periodicity=3.0, length_scale_bounds=(0.1, 10.0), periodicity_bounds=(1.0, 10.0)),\n",
    "                  1*Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)+1*WhiteKernel(noise_level=0.5),\n",
    "                ]\n",
    "\n",
    "\n",
    "dataDir = Path.cwd().parent.parent/'Data/processed'\n",
    "ts_dataset = pd.read_csv(dataDir/\"learner_118_new_meanTimeCost_minPara.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['kernel'] = [1*RBF(), 1*DotProduct(), 1*Matern(),  1*RationalQuadratic(),1*Matern()+1*WhiteKernel(noise_level=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 64-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 57-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 67-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 66-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 72-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 63-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 59-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 62-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 68-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 65-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 69-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 56-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 55-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 61-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 50-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 45-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 40-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 48-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 39-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 46-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 44-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 51-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 41-th leading minor of the array is not positive definite\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 715, in fit\n",
      "    self.base_estimator_.fit(X, y)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 224, in fit\n",
      "    self._constrained_optimization(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 469, in _constrained_optimization\n",
      "    opt_res = scipy.optimize.minimize(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 681, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 308, in _minimize_lbfgsb\n",
      "    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 263, in _prepare_scalar_function\n",
      "    sf = ScalarFunction(fun, x0, args, grad, hess,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 158, in __init__\n",
      "    self._update_fun()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 215, in obj_func\n",
      "    lml, grad = self.log_marginal_likelihood(\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 380, in log_marginal_likelihood\n",
      "    Z, (pi, W_sr, L, b, a) = self._posterior_mode(K, return_temporaries=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\_gpc.py\", line 439, in _posterior_mode\n",
      "    L = cholesky(B, lower=True)\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 88, in cholesky\n",
      "    c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n",
      "  File \"d:\\Toolbox\\python\\lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py\", line 37, in _cholesky\n",
      "    raise LinAlgError(\"%d-th leading minor of the array is not positive \"\n",
      "numpy.linalg.LinAlgError: 52-th leading minor of the array is not positive definite\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.94601449 0.94775362 0.94782609 0.94601449 0.94782609        nan\n",
      "        nan 0.94942029]\n",
      "  warnings.warn(\n",
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.9494202898550725\n",
      "Best estimator parameters:  {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy 0.946 with: {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "Accuracy 0.948 with: {'kernel': 1**2 * DotProduct(sigma_0=1)}\n",
      "Accuracy 0.948 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5)}\n",
      "Accuracy 0.946 with: {'kernel': 1**2 * RationalQuadratic(alpha=1, length_scale=1)}\n",
      "Accuracy 0.948 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=1)}\n",
      "Accuracy nan with: {'kernel': 1**2 * ExpSineSquared(length_scale=1, periodicity=3)}\n",
      "Accuracy 0.949 with: {'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Toolbox\\python\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ts_dataset.iloc[:, 0:len(ts_dataset.columns)-1].copy()\n",
    "y = pd.DataFrame(ts_dataset.iloc[:, -1])\n",
    "# split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=68)\n",
    "model = GaussianProcessClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=5)\n",
    "# exhausive search over different kernels\n",
    "search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# fit model into the dataset\n",
    "result = search.fit(X, y)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", result.best_score_)\n",
    "print(\"Best estimator parameters: \", result.best_params_)\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"Accuracy %.3f with: %r\" % (mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        48\n",
       "0        40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        15\n",
       "1        15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  0.9886363636363636\n",
      "Mean accuracy on training data:  1.0\n",
      "Log Marginal Likelihood: -57.974\n",
      "Log Marginal Likelihood: -19.592\n",
      "Log-loss: 0.504 (initial) 0.136 (optimized)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method GaussianProcessClassifier.predict_proba of GaussianProcessClassifier(kernel=1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5),\n",
       "                          n_jobs=-1, random_state=18)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_kernel = 1*DotProduct()\n",
    "best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "\n",
    "model_ini = GaussianProcessClassifier(kernel=best_kernel, random_state=10, n_jobs=-1, optimizer=None)\n",
    "model_ini.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model_ini.score(X_train, y_train))\n",
    "\n",
    "model_opt = GaussianProcessClassifier(kernel=best_kernel, random_state=18, n_jobs=-1)\n",
    "model_opt.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model_opt.score(X_train, y_train))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Log Marginal Likelihood: %.3f\"\n",
    "    % model_ini.log_marginal_likelihood(model_ini.kernel_.theta)\n",
    ")\n",
    "print(\n",
    "    \"Log Marginal Likelihood: %.3f\"\n",
    "    % model_opt.log_marginal_likelihood(model_opt.kernel_.theta)\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Log-loss: %.3f (initial) %.3f (optimized)\"\n",
    "    % (\n",
    "        log_loss(y_train, model_ini.predict_proba(X_train)[:, 1]),\n",
    "        log_loss(y_train, model_opt.predict_proba(X_train)[:, 1]),\n",
    "    )\n",
    ")\n",
    "\n",
    "model_opt.predict_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'GPC-Matern_WhiteKernel-Train'),\n",
       " Text(0.5, 0, 'Predicted probability(positive class)'),\n",
       " Text(0, 0.5, 'Count')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.hist(\n",
    "    model_opt.predict_proba(X_train)[:,1],\n",
    "    range=(0, 1),\n",
    "    bins=10,\n",
    "    label=\"GP\",\n",
    "    color=colors(1),\n",
    "    )\n",
    "ax.set(title=\"GPC-Matern_WhiteKernel-Train\", xlabel=\"Predicted probability(positive class)\", ylabel=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        63\n",
       "0        55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0        15\n",
       "1        15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2106046 , 0.84047319, 0.85173971, 0.1444538 , 0.81162486,\n",
       "       0.19780321, 0.25079181, 0.20313554, 0.95650529, 0.96846936,\n",
       "       0.95593061, 0.92634373, 0.74389922, 0.74282412, 0.84529774,\n",
       "       0.72905025, 0.8075667 , 0.73843693, 0.15658514, 0.21835854,\n",
       "       0.95920903, 0.22004996, 0.95823759, 0.81617219, 0.7962108 ,\n",
       "       0.93518495, 0.93215651, 0.30517105, 0.71734829, 0.85278873,\n",
       "       0.93615969, 0.80153155, 0.80547532, 0.74231205, 0.69406327,\n",
       "       0.09633175, 0.17948264, 0.82984861, 0.83789983, 0.92028683,\n",
       "       0.93042304, 0.76940379, 0.24757791, 0.19201591, 0.75919633,\n",
       "       0.19194801, 0.90401086, 0.92347138, 0.90456991, 0.75507705,\n",
       "       0.78166977, 0.9528812 , 0.71305654, 0.84248292, 0.76890422,\n",
       "       0.85726648, 0.88614933, 0.8242286 , 0.75170263, 0.75113801,\n",
       "       0.75843072, 0.20602955, 0.81633134, 0.82935454, 0.92281863,\n",
       "       0.74888475, 0.85055077, 0.93370087, 0.19511675, 0.88011106,\n",
       "       0.72856978, 0.75051339, 0.72623344, 0.29068142, 0.91331638,\n",
       "       0.63178673, 0.66339779, 0.8786773 , 0.26290279, 0.80428879,\n",
       "       0.22934656, 0.84476745, 0.26009462, 0.91881861, 0.29195558,\n",
       "       0.18832603, 0.73878625])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opt.predict_proba(X_train)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on training data:  1.0\n",
      "Prediction on test data:  [1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1]\n",
      "Prediction accuracy on test data:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# best_kernel = 1*DotProduct()\n",
    "# best_kernel = 1**2 * RationalQuadratic(alpha=1, length_scale=1)\n",
    "best_kernel = 1**2 * Matern(length_scale=1, nu=1.5) + 1**2 * WhiteKernel(noise_level=0.5)\n",
    "# best_kernel = 1**2 * Matern(length_scale=1, nu=1.5)\n",
    "# best_kernel = 1**2 * RBF(length_scale=1)\n",
    "model = GaussianProcessClassifier(kernel=best_kernel, random_state=30, n_jobs=-1)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "print(\"Mean accuracy on training data: \", model.score(X_train, y_train))\n",
    "print(\"Prediction on test data: \", model.predict(X_test))\n",
    "pred_test = model.predict(X_test)\n",
    "print(\"Prediction accuracy on test data: \", accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>Age__standard_deviation</th>\n",
       "      <th>Age__variance</th>\n",
       "      <th>Total_MilkProduction__sum_values</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>milking_times__mean.1</th>\n",
       "      <th>milking_times__root_mean_square.1</th>\n",
       "      <th>milking_times__length.1</th>\n",
       "      <th>milking_times__maximum.1</th>\n",
       "      <th>milking_times__absolute_maximum.1</th>\n",
       "      <th>milking_times__median.1</th>\n",
       "      <th>milking_times__standard_deviation.1</th>\n",
       "      <th>milking_times__variance.1</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.524434</td>\n",
       "      <td>1.085858</td>\n",
       "      <td>1.079378</td>\n",
       "      <td>1.101637</td>\n",
       "      <td>0.514914</td>\n",
       "      <td>1.085858</td>\n",
       "      <td>0.047985</td>\n",
       "      <td>-0.117160</td>\n",
       "      <td>0.251880</td>\n",
       "      <td>0.089892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007509</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>-1.393442</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.402734</td>\n",
       "      <td>-0.443021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008898</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>0.470140</td>\n",
       "      <td>0.425319</td>\n",
       "      <td>1.514386</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>0.292065</td>\n",
       "      <td>0.279305</td>\n",
       "      <td>0.312188</td>\n",
       "      <td>0.153706</td>\n",
       "      <td>...</td>\n",
       "      <td>2.806171</td>\n",
       "      <td>2.782333</td>\n",
       "      <td>-1.826475</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1.469615</td>\n",
       "      <td>-1.431467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.266430</td>\n",
       "      <td>-0.032117</td>\n",
       "      <td>-0.142078</td>\n",
       "      <td>-0.206394</td>\n",
       "      <td>0.080839</td>\n",
       "      <td>-0.032117</td>\n",
       "      <td>-1.373574</td>\n",
       "      <td>-1.252952</td>\n",
       "      <td>-1.441097</td>\n",
       "      <td>-1.215417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.956602</td>\n",
       "      <td>-1.281174</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.528312</td>\n",
       "      <td>0.501252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.248974</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>0.117640</td>\n",
       "      <td>0.055729</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>0.716305</td>\n",
       "      <td>0.743236</td>\n",
       "      <td>0.666859</td>\n",
       "      <td>0.553087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148210</td>\n",
       "      <td>0.164350</td>\n",
       "      <td>0.130193</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.539564</td>\n",
       "      <td>0.513130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.342294</td>\n",
       "      <td>1.553847</td>\n",
       "      <td>1.710117</td>\n",
       "      <td>1.851932</td>\n",
       "      <td>1.268918</td>\n",
       "      <td>1.553847</td>\n",
       "      <td>-0.452687</td>\n",
       "      <td>-0.203410</td>\n",
       "      <td>-0.745908</td>\n",
       "      <td>-0.793001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848795</td>\n",
       "      <td>-0.811337</td>\n",
       "      <td>0.402843</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.941142</td>\n",
       "      <td>0.944306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.014733</td>\n",
       "      <td>-1.124092</td>\n",
       "      <td>-1.009327</td>\n",
       "      <td>-1.019051</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>-1.124092</td>\n",
       "      <td>-1.703311</td>\n",
       "      <td>-1.455537</td>\n",
       "      <td>-1.927615</td>\n",
       "      <td>-1.416896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686537</td>\n",
       "      <td>-0.644701</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.071787</td>\n",
       "      <td>1.087634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.265372</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>0.529172</td>\n",
       "      <td>0.488770</td>\n",
       "      <td>-1.340405</td>\n",
       "      <td>0.617868</td>\n",
       "      <td>-0.854216</td>\n",
       "      <td>-0.823393</td>\n",
       "      <td>-0.836862</td>\n",
       "      <td>-0.857266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.469579</td>\n",
       "      <td>-0.449131</td>\n",
       "      <td>-0.463223</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.610262</td>\n",
       "      <td>0.588011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.137415</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>0.510070</td>\n",
       "      <td>0.468189</td>\n",
       "      <td>-0.916507</td>\n",
       "      <td>0.565870</td>\n",
       "      <td>1.163018</td>\n",
       "      <td>0.932482</td>\n",
       "      <td>1.401886</td>\n",
       "      <td>1.511931</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057144</td>\n",
       "      <td>1.070814</td>\n",
       "      <td>-1.617978</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.412278</td>\n",
       "      <td>0.379418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.777087</td>\n",
       "      <td>-0.812099</td>\n",
       "      <td>-0.787309</td>\n",
       "      <td>-0.820187</td>\n",
       "      <td>-1.244746</td>\n",
       "      <td>-0.812099</td>\n",
       "      <td>-0.493014</td>\n",
       "      <td>-0.482371</td>\n",
       "      <td>-0.466806</td>\n",
       "      <td>-0.578883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343693</td>\n",
       "      <td>-0.365859</td>\n",
       "      <td>0.787762</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.452701</td>\n",
       "      <td>-0.491545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.866793</td>\n",
       "      <td>1.501849</td>\n",
       "      <td>1.534682</td>\n",
       "      <td>1.638126</td>\n",
       "      <td>1.145617</td>\n",
       "      <td>1.501849</td>\n",
       "      <td>-0.450061</td>\n",
       "      <td>-0.736638</td>\n",
       "      <td>-0.117250</td>\n",
       "      <td>-0.274731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230736</td>\n",
       "      <td>-0.277878</td>\n",
       "      <td>-0.896256</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.146235</td>\n",
       "      <td>-1.142418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.493985</td>\n",
       "      <td>-1.774078</td>\n",
       "      <td>-1.728078</td>\n",
       "      <td>-1.619521</td>\n",
       "      <td>-0.835757</td>\n",
       "      <td>-1.774078</td>\n",
       "      <td>-0.253874</td>\n",
       "      <td>-0.261022</td>\n",
       "      <td>-0.216664</td>\n",
       "      <td>-0.365304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.878951</td>\n",
       "      <td>-0.900088</td>\n",
       "      <td>0.948144</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.434538</td>\n",
       "      <td>-0.473932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.468623</td>\n",
       "      <td>-1.566082</td>\n",
       "      <td>-1.462721</td>\n",
       "      <td>-1.405541</td>\n",
       "      <td>-1.972024</td>\n",
       "      <td>-1.566082</td>\n",
       "      <td>0.337339</td>\n",
       "      <td>0.164147</td>\n",
       "      <td>0.540952</td>\n",
       "      <td>0.406592</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.540621</td>\n",
       "      <td>-1.578647</td>\n",
       "      <td>0.675494</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.903357</td>\n",
       "      <td>-0.919286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.077756</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>0.143323</td>\n",
       "      <td>0.082119</td>\n",
       "      <td>-0.295360</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>1.072410</td>\n",
       "      <td>0.714301</td>\n",
       "      <td>1.451905</td>\n",
       "      <td>1.583611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003606</td>\n",
       "      <td>0.026885</td>\n",
       "      <td>1.317025</td>\n",
       "      <td>2.262742</td>\n",
       "      <td>2.262742</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.894960</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.305019</td>\n",
       "      <td>-1.514084</td>\n",
       "      <td>-1.611870</td>\n",
       "      <td>-1.526924</td>\n",
       "      <td>-0.295093</td>\n",
       "      <td>-1.514084</td>\n",
       "      <td>-0.052647</td>\n",
       "      <td>0.109351</td>\n",
       "      <td>-0.241790</td>\n",
       "      <td>-0.387683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144356</td>\n",
       "      <td>-0.088775</td>\n",
       "      <td>0.948144</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>1.060660</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.478852</td>\n",
       "      <td>1.543825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.132805</td>\n",
       "      <td>0.045881</td>\n",
       "      <td>0.047668</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.371351</td>\n",
       "      <td>0.045881</td>\n",
       "      <td>-0.749968</td>\n",
       "      <td>-0.588997</td>\n",
       "      <td>-0.901028</td>\n",
       "      <td>-0.900974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397711</td>\n",
       "      <td>-0.349167</td>\n",
       "      <td>0.146231</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.276423</td>\n",
       "      <td>1.315147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.270390</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>-0.012724</td>\n",
       "      <td>-0.076922</td>\n",
       "      <td>1.462701</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>2.640457</td>\n",
       "      <td>3.055026</td>\n",
       "      <td>1.926947</td>\n",
       "      <td>2.305212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532720</td>\n",
       "      <td>0.485411</td>\n",
       "      <td>0.675494</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.305924</td>\n",
       "      <td>-1.286302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.772878</td>\n",
       "      <td>0.513871</td>\n",
       "      <td>0.611917</td>\n",
       "      <td>0.578460</td>\n",
       "      <td>0.535894</td>\n",
       "      <td>0.513871</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>-0.076369</td>\n",
       "      <td>0.342403</td>\n",
       "      <td>0.186123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.946518</td>\n",
       "      <td>-1.014034</td>\n",
       "      <td>0.466997</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-1.343503</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.638476</td>\n",
       "      <td>-1.578751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age__sum_values  Age__length  Age__standard_deviation  Age__variance  \\\n",
       "id                                                                         \n",
       "1          0.524434     1.085858                 1.079378       1.101637   \n",
       "2         -0.008898     0.565870                 0.470140       0.425319   \n",
       "3         -0.266430    -0.032117                -0.142078      -0.206394   \n",
       "4         -0.248974     0.123880                 0.117640       0.055729   \n",
       "5          1.342294     1.553847                 1.710117       1.851932   \n",
       "6         -1.014733    -1.124092                -1.009327      -1.019051   \n",
       "7          0.265372     0.617868                 0.529172       0.488770   \n",
       "8          0.137415     0.565870                 0.510070       0.468189   \n",
       "9         -0.777087    -0.812099                -0.787309      -0.820187   \n",
       "10         2.866793     1.501849                 1.534682       1.638126   \n",
       "11        -1.493985    -1.774078                -1.728078      -1.619521   \n",
       "12        -0.468623    -1.566082                -1.462721      -1.405541   \n",
       "13         0.077756     0.123880                 0.143323       0.082119   \n",
       "14        -1.305019    -1.514084                -1.611870      -1.526924   \n",
       "15        -0.132805     0.045881                 0.047668      -0.015741   \n",
       "16        -0.270390     0.123880                -0.012724      -0.076922   \n",
       "17         0.772878     0.513871                 0.611917       0.578460   \n",
       "\n",
       "    Total_MilkProduction__sum_values  Total_MilkProduction__length  \\\n",
       "id                                                                   \n",
       "1                           0.514914                      1.085858   \n",
       "2                           1.514386                      0.565870   \n",
       "3                           0.080839                     -0.032117   \n",
       "4                          -0.001418                      0.123880   \n",
       "5                           1.268918                      1.553847   \n",
       "6                           0.006688                     -1.124092   \n",
       "7                          -1.340405                      0.617868   \n",
       "8                          -0.916507                      0.565870   \n",
       "9                          -1.244746                     -0.812099   \n",
       "10                          1.145617                      1.501849   \n",
       "11                         -0.835757                     -1.774078   \n",
       "12                         -1.972024                     -1.566082   \n",
       "13                         -0.295360                      0.123880   \n",
       "14                         -0.295093                     -1.514084   \n",
       "15                          0.371351                      0.045881   \n",
       "16                          1.462701                      0.123880   \n",
       "17                          0.535894                      0.513871   \n",
       "\n",
       "    Total_timeDelta_Seconds__root_mean_square  Total_timeDelta_Seconds__mean  \\\n",
       "id                                                                             \n",
       "1                                    0.047985                      -0.117160   \n",
       "2                                    0.292065                       0.279305   \n",
       "3                                   -1.373574                      -1.252952   \n",
       "4                                    0.716305                       0.743236   \n",
       "5                                   -0.452687                      -0.203410   \n",
       "6                                   -1.703311                      -1.455537   \n",
       "7                                   -0.854216                      -0.823393   \n",
       "8                                    1.163018                       0.932482   \n",
       "9                                   -0.493014                      -0.482371   \n",
       "10                                  -0.450061                      -0.736638   \n",
       "11                                  -0.253874                      -0.261022   \n",
       "12                                   0.337339                       0.164147   \n",
       "13                                   1.072410                       0.714301   \n",
       "14                                  -0.052647                       0.109351   \n",
       "15                                  -0.749968                      -0.588997   \n",
       "16                                   2.640457                       3.055026   \n",
       "17                                   0.113773                      -0.076369   \n",
       "\n",
       "    Total_timeDelta_Seconds__standard_deviation  \\\n",
       "id                                                \n",
       "1                                      0.251880   \n",
       "2                                      0.312188   \n",
       "3                                     -1.441097   \n",
       "4                                      0.666859   \n",
       "5                                     -0.745908   \n",
       "6                                     -1.927615   \n",
       "7                                     -0.836862   \n",
       "8                                      1.401886   \n",
       "9                                     -0.466806   \n",
       "10                                    -0.117250   \n",
       "11                                    -0.216664   \n",
       "12                                     0.540952   \n",
       "13                                     1.451905   \n",
       "14                                    -0.241790   \n",
       "15                                    -0.901028   \n",
       "16                                     1.926947   \n",
       "17                                     0.342403   \n",
       "\n",
       "    Total_timeDelta_Seconds__variance  ...  milking_times__mean.1  \\\n",
       "id                                     ...                          \n",
       "1                            0.089892  ...               1.007509   \n",
       "2                            0.153706  ...               2.806171   \n",
       "3                           -1.215417  ...               0.939348   \n",
       "4                            0.553087  ...               0.148210   \n",
       "5                           -0.793001  ...              -0.848795   \n",
       "6                           -1.416896  ...              -0.686537   \n",
       "7                           -0.857266  ...              -0.469579   \n",
       "8                            1.511931  ...               1.057144   \n",
       "9                           -0.578883  ...              -0.343693   \n",
       "10                          -0.274731  ...              -0.230736   \n",
       "11                          -0.365304  ...              -0.878951   \n",
       "12                           0.406592  ...              -1.540621   \n",
       "13                           1.583611  ...              -0.003606   \n",
       "14                          -0.387683  ...              -0.144356   \n",
       "15                          -0.900974  ...              -0.397711   \n",
       "16                           2.305212  ...               0.532720   \n",
       "17                           0.186123  ...              -0.946518   \n",
       "\n",
       "    milking_times__root_mean_square.1  milking_times__length.1  \\\n",
       "id                                                               \n",
       "1                            0.993223                -1.393442   \n",
       "2                            2.782333                -1.826475   \n",
       "3                            0.956602                -1.281174   \n",
       "4                            0.164350                 0.130193   \n",
       "5                           -0.811337                 0.402843   \n",
       "6                           -0.644701                 0.980221   \n",
       "7                           -0.449131                -0.463223   \n",
       "8                            1.070814                -1.617978   \n",
       "9                           -0.365859                 0.787762   \n",
       "10                          -0.277878                -0.896256   \n",
       "11                          -0.900088                 0.948144   \n",
       "12                          -1.578647                 0.675494   \n",
       "13                           0.026885                 1.317025   \n",
       "14                          -0.088775                 0.948144   \n",
       "15                          -0.349167                 0.146231   \n",
       "16                           0.485411                 0.675494   \n",
       "17                          -1.014034                 0.466997   \n",
       "\n",
       "    milking_times__maximum.1  milking_times__absolute_maximum.1  \\\n",
       "id                                                                \n",
       "1                  -0.141421                          -0.141421   \n",
       "2                   1.060660                           1.060660   \n",
       "3                   1.060660                           1.060660   \n",
       "4                  -0.141421                          -0.141421   \n",
       "5                  -1.343503                          -1.343503   \n",
       "6                  -0.141421                          -0.141421   \n",
       "7                  -0.141421                          -0.141421   \n",
       "8                   1.060660                           1.060660   \n",
       "9                  -0.141421                          -0.141421   \n",
       "10                 -1.343503                          -1.343503   \n",
       "11                 -1.343503                          -1.343503   \n",
       "12                 -0.141421                          -0.141421   \n",
       "13                  2.262742                           2.262742   \n",
       "14                  1.060660                           1.060660   \n",
       "15                 -0.141421                          -0.141421   \n",
       "16                 -0.141421                          -0.141421   \n",
       "17                 -1.343503                          -1.343503   \n",
       "\n",
       "    milking_times__median.1  milking_times__standard_deviation.1  \\\n",
       "id                                                                 \n",
       "1                     -0.25                            -0.402734   \n",
       "2                      4.00                            -1.469615   \n",
       "3                     -0.25                             0.528312   \n",
       "4                     -0.25                             0.539564   \n",
       "5                     -0.25                             0.941142   \n",
       "6                     -0.25                             1.071787   \n",
       "7                     -0.25                             0.610262   \n",
       "8                     -0.25                             0.412278   \n",
       "9                     -0.25                            -0.452701   \n",
       "10                    -0.25                            -1.146235   \n",
       "11                    -0.25                            -0.434538   \n",
       "12                    -0.25                            -0.903357   \n",
       "13                    -0.25                             0.894960   \n",
       "14                    -0.25                             1.478852   \n",
       "15                    -0.25                             1.276423   \n",
       "16                    -0.25                            -1.305924   \n",
       "17                    -0.25                            -1.638476   \n",
       "\n",
       "    milking_times__variance.1  BreedName_1  BreedName_2  \n",
       "id                                                       \n",
       "1                   -0.443021          0.0          1.0  \n",
       "2                   -1.431467          0.0          1.0  \n",
       "3                    0.501252          1.0          0.0  \n",
       "4                    0.513130          1.0          0.0  \n",
       "5                    0.944306          1.0          0.0  \n",
       "6                    1.087634          1.0          0.0  \n",
       "7                    0.588011          1.0          0.0  \n",
       "8                    0.379418          0.0          1.0  \n",
       "9                   -0.491545          1.0          0.0  \n",
       "10                  -1.142418          0.0          1.0  \n",
       "11                  -0.473932          0.0          1.0  \n",
       "12                  -0.919286          1.0          0.0  \n",
       "13                   0.894000          0.0          1.0  \n",
       "14                   1.543825          0.0          1.0  \n",
       "15                   1.315147          1.0          0.0  \n",
       "16                  -1.286302          0.0          1.0  \n",
       "17                  -1.578751          0.0          1.0  \n",
       "\n",
       "[17 rows x 58 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        63\n",
       "0        55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DaysInMilk__sum_values</th>\n",
       "      <th>DaysInMilk__minimum</th>\n",
       "      <th>Age__sum_values</th>\n",
       "      <th>Age__length</th>\n",
       "      <th>DaysInMilk__length</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__length</th>\n",
       "      <th>milking_times__length</th>\n",
       "      <th>Total_MilkProduction__length</th>\n",
       "      <th>Total_MilkProduction__sum_values</th>\n",
       "      <th>milking_times__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__absolute_maximum</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__standard_deviation</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__variance</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__median</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>mean_Total_timeDelta_Seconds__mean</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.110237</td>\n",
       "      <td>-0.528062</td>\n",
       "      <td>0.333358</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.501672</td>\n",
       "      <td>-0.548284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.041292</td>\n",
       "      <td>-1.025806</td>\n",
       "      <td>-0.642167</td>\n",
       "      <td>-1.030430</td>\n",
       "      <td>-1.058140</td>\n",
       "      <td>-1.056369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.055223</td>\n",
       "      <td>-0.377914</td>\n",
       "      <td>0.471188</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>1.070130</td>\n",
       "      <td>-0.594408</td>\n",
       "      <td>...</td>\n",
       "      <td>2.509894</td>\n",
       "      <td>1.696769</td>\n",
       "      <td>1.582869</td>\n",
       "      <td>0.707281</td>\n",
       "      <td>1.412190</td>\n",
       "      <td>0.996408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.448078</td>\n",
       "      <td>-0.427963</td>\n",
       "      <td>1.156090</td>\n",
       "      <td>1.236986</td>\n",
       "      <td>1.236986</td>\n",
       "      <td>1.236986</td>\n",
       "      <td>1.236986</td>\n",
       "      <td>1.236986</td>\n",
       "      <td>2.250353</td>\n",
       "      <td>0.635476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532950</td>\n",
       "      <td>0.176336</td>\n",
       "      <td>-0.143899</td>\n",
       "      <td>0.450596</td>\n",
       "      <td>0.209832</td>\n",
       "      <td>0.262504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.243570</td>\n",
       "      <td>0.623070</td>\n",
       "      <td>0.528448</td>\n",
       "      <td>0.644028</td>\n",
       "      <td>0.644028</td>\n",
       "      <td>0.644028</td>\n",
       "      <td>0.644028</td>\n",
       "      <td>0.644028</td>\n",
       "      <td>0.843482</td>\n",
       "      <td>-0.209938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.646198</td>\n",
       "      <td>-0.700438</td>\n",
       "      <td>-0.582878</td>\n",
       "      <td>-0.747602</td>\n",
       "      <td>-0.733155</td>\n",
       "      <td>-0.738422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.169675</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>0.239230</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.664145</td>\n",
       "      <td>0.057348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.945139</td>\n",
       "      <td>-0.912552</td>\n",
       "      <td>-0.627894</td>\n",
       "      <td>-0.918114</td>\n",
       "      <td>-0.942865</td>\n",
       "      <td>-0.940886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.132798</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>0.118615</td>\n",
       "      <td>0.414106</td>\n",
       "      <td>0.414106</td>\n",
       "      <td>0.414106</td>\n",
       "      <td>0.414106</td>\n",
       "      <td>0.414106</td>\n",
       "      <td>0.620467</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934918</td>\n",
       "      <td>-0.861258</td>\n",
       "      <td>-0.619193</td>\n",
       "      <td>-0.900730</td>\n",
       "      <td>-0.895698</td>\n",
       "      <td>-0.899492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.147576</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>0.389904</td>\n",
       "      <td>0.389904</td>\n",
       "      <td>0.389904</td>\n",
       "      <td>0.389904</td>\n",
       "      <td>0.389904</td>\n",
       "      <td>0.600703</td>\n",
       "      <td>1.946572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.973999</td>\n",
       "      <td>-0.969377</td>\n",
       "      <td>-0.635905</td>\n",
       "      <td>-0.965852</td>\n",
       "      <td>-1.001006</td>\n",
       "      <td>-0.999429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.929461</td>\n",
       "      <td>-0.277816</td>\n",
       "      <td>-1.327105</td>\n",
       "      <td>-1.497879</td>\n",
       "      <td>-1.497879</td>\n",
       "      <td>-1.497879</td>\n",
       "      <td>-1.497879</td>\n",
       "      <td>-1.497879</td>\n",
       "      <td>-1.573042</td>\n",
       "      <td>-0.519888</td>\n",
       "      <td>...</td>\n",
       "      <td>2.345705</td>\n",
       "      <td>2.587185</td>\n",
       "      <td>3.162783</td>\n",
       "      <td>2.130044</td>\n",
       "      <td>2.561090</td>\n",
       "      <td>2.488318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.213278</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>-0.024831</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>0.268892</td>\n",
       "      <td>-0.163308</td>\n",
       "      <td>2.285260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902643</td>\n",
       "      <td>-0.831281</td>\n",
       "      <td>-0.613463</td>\n",
       "      <td>-0.893125</td>\n",
       "      <td>-0.871022</td>\n",
       "      <td>-0.881779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.234509</td>\n",
       "      <td>-0.077619</td>\n",
       "      <td>-0.402192</td>\n",
       "      <td>-0.420875</td>\n",
       "      <td>-0.420875</td>\n",
       "      <td>-0.420875</td>\n",
       "      <td>-0.420875</td>\n",
       "      <td>-0.420875</td>\n",
       "      <td>0.111686</td>\n",
       "      <td>-0.361969</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817240</td>\n",
       "      <td>-0.818229</td>\n",
       "      <td>-0.610819</td>\n",
       "      <td>-0.793643</td>\n",
       "      <td>-0.835462</td>\n",
       "      <td>-0.820762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.102808</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>0.100144</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>1.337947</td>\n",
       "      <td>2.114234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720097</td>\n",
       "      <td>-0.604393</td>\n",
       "      <td>-0.554655</td>\n",
       "      <td>-0.184676</td>\n",
       "      <td>-0.521655</td>\n",
       "      <td>-0.410717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005303</td>\n",
       "      <td>-0.377914</td>\n",
       "      <td>0.431217</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.595624</td>\n",
       "      <td>0.816906</td>\n",
       "      <td>-0.065255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334885</td>\n",
       "      <td>0.185630</td>\n",
       "      <td>-0.137064</td>\n",
       "      <td>-0.124362</td>\n",
       "      <td>0.105718</td>\n",
       "      <td>0.019451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.117454</td>\n",
       "      <td>1.273710</td>\n",
       "      <td>-0.419148</td>\n",
       "      <td>-0.832314</td>\n",
       "      <td>-0.832314</td>\n",
       "      <td>-0.832314</td>\n",
       "      <td>-0.832314</td>\n",
       "      <td>-0.832314</td>\n",
       "      <td>-1.376489</td>\n",
       "      <td>-0.371229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544416</td>\n",
       "      <td>-0.693198</td>\n",
       "      <td>-0.580921</td>\n",
       "      <td>-0.631008</td>\n",
       "      <td>-0.712217</td>\n",
       "      <td>-0.701781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.809067</td>\n",
       "      <td>-0.327865</td>\n",
       "      <td>-1.155215</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-1.051426</td>\n",
       "      <td>-0.671042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021667</td>\n",
       "      <td>1.834131</td>\n",
       "      <td>1.799196</td>\n",
       "      <td>1.912881</td>\n",
       "      <td>2.086804</td>\n",
       "      <td>2.348882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.017718</td>\n",
       "      <td>-0.277816</td>\n",
       "      <td>0.661475</td>\n",
       "      <td>0.547219</td>\n",
       "      <td>0.547219</td>\n",
       "      <td>0.547219</td>\n",
       "      <td>0.547219</td>\n",
       "      <td>0.547219</td>\n",
       "      <td>1.088563</td>\n",
       "      <td>0.033272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725999</td>\n",
       "      <td>-0.132130</td>\n",
       "      <td>-0.344779</td>\n",
       "      <td>-0.227376</td>\n",
       "      <td>-0.194232</td>\n",
       "      <td>-0.249650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.851150</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>-1.173058</td>\n",
       "      <td>-1.292159</td>\n",
       "      <td>-1.292159</td>\n",
       "      <td>-1.292159</td>\n",
       "      <td>-1.292159</td>\n",
       "      <td>-1.292159</td>\n",
       "      <td>-1.485384</td>\n",
       "      <td>-0.758146</td>\n",
       "      <td>...</td>\n",
       "      <td>1.599719</td>\n",
       "      <td>3.465402</td>\n",
       "      <td>5.132512</td>\n",
       "      <td>2.827777</td>\n",
       "      <td>3.566510</td>\n",
       "      <td>3.628231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.927048</td>\n",
       "      <td>0.072529</td>\n",
       "      <td>-1.509302</td>\n",
       "      <td>-1.764104</td>\n",
       "      <td>-1.764104</td>\n",
       "      <td>-1.764104</td>\n",
       "      <td>-1.764104</td>\n",
       "      <td>-1.764104</td>\n",
       "      <td>-1.229845</td>\n",
       "      <td>1.804892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289513</td>\n",
       "      <td>-0.028211</td>\n",
       "      <td>-0.282736</td>\n",
       "      <td>-0.253859</td>\n",
       "      <td>-0.083263</td>\n",
       "      <td>-0.131920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-0.102835</td>\n",
       "      <td>-0.427963</td>\n",
       "      <td>0.285814</td>\n",
       "      <td>0.450410</td>\n",
       "      <td>0.450410</td>\n",
       "      <td>0.450410</td>\n",
       "      <td>0.450410</td>\n",
       "      <td>0.450410</td>\n",
       "      <td>0.634966</td>\n",
       "      <td>1.842604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.834431</td>\n",
       "      <td>-0.840283</td>\n",
       "      <td>-0.615234</td>\n",
       "      <td>-0.733003</td>\n",
       "      <td>-0.832581</td>\n",
       "      <td>-0.792078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216020</td>\n",
       "      <td>0.322775</td>\n",
       "      <td>0.290838</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.308734</td>\n",
       "      <td>2.746202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960752</td>\n",
       "      <td>-0.856261</td>\n",
       "      <td>-0.618271</td>\n",
       "      <td>-0.521815</td>\n",
       "      <td>-0.789429</td>\n",
       "      <td>-0.696952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.524251</td>\n",
       "      <td>5.177550</td>\n",
       "      <td>1.173674</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>-0.787655</td>\n",
       "      <td>-0.847223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717027</td>\n",
       "      <td>0.506491</td>\n",
       "      <td>0.126959</td>\n",
       "      <td>0.521490</td>\n",
       "      <td>0.556243</td>\n",
       "      <td>0.620812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.518873</td>\n",
       "      <td>-0.528062</td>\n",
       "      <td>-0.478587</td>\n",
       "      <td>-0.275661</td>\n",
       "      <td>-0.275661</td>\n",
       "      <td>-0.275661</td>\n",
       "      <td>-0.275661</td>\n",
       "      <td>-0.275661</td>\n",
       "      <td>0.210789</td>\n",
       "      <td>1.371108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>-0.525083</td>\n",
       "      <td>-0.527665</td>\n",
       "      <td>-0.137638</td>\n",
       "      <td>-0.438222</td>\n",
       "      <td>-0.322960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.418494</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>0.762216</td>\n",
       "      <td>1.128075</td>\n",
       "      <td>1.128075</td>\n",
       "      <td>1.128075</td>\n",
       "      <td>1.128075</td>\n",
       "      <td>1.128075</td>\n",
       "      <td>1.234561</td>\n",
       "      <td>0.900149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.806030</td>\n",
       "      <td>-0.847836</td>\n",
       "      <td>-0.616686</td>\n",
       "      <td>-0.682990</td>\n",
       "      <td>-0.832080</td>\n",
       "      <td>-0.783870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.890523</td>\n",
       "      <td>-0.528062</td>\n",
       "      <td>-1.085727</td>\n",
       "      <td>-1.207450</td>\n",
       "      <td>-1.207450</td>\n",
       "      <td>-1.207450</td>\n",
       "      <td>-1.207450</td>\n",
       "      <td>-1.207450</td>\n",
       "      <td>-0.588661</td>\n",
       "      <td>-0.063863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482174</td>\n",
       "      <td>-0.393157</td>\n",
       "      <td>-0.475387</td>\n",
       "      <td>-0.087490</td>\n",
       "      <td>-0.352834</td>\n",
       "      <td>-0.283444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.263194</td>\n",
       "      <td>1.774203</td>\n",
       "      <td>3.089442</td>\n",
       "      <td>2.604418</td>\n",
       "      <td>2.604418</td>\n",
       "      <td>2.604418</td>\n",
       "      <td>2.604418</td>\n",
       "      <td>2.604418</td>\n",
       "      <td>2.284615</td>\n",
       "      <td>-1.216847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>0.170602</td>\n",
       "      <td>-0.148093</td>\n",
       "      <td>0.782656</td>\n",
       "      <td>0.343251</td>\n",
       "      <td>0.539902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.741521</td>\n",
       "      <td>-0.528062</td>\n",
       "      <td>-0.718303</td>\n",
       "      <td>-0.783910</td>\n",
       "      <td>-0.783910</td>\n",
       "      <td>-0.783910</td>\n",
       "      <td>-0.783910</td>\n",
       "      <td>-0.783910</td>\n",
       "      <td>-0.264939</td>\n",
       "      <td>-0.598840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705108</td>\n",
       "      <td>-0.627169</td>\n",
       "      <td>-0.561790</td>\n",
       "      <td>-0.266761</td>\n",
       "      <td>-0.543975</td>\n",
       "      <td>-0.432866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.378932</td>\n",
       "      <td>-0.377914</td>\n",
       "      <td>-0.050838</td>\n",
       "      <td>-0.759707</td>\n",
       "      <td>-0.759707</td>\n",
       "      <td>-0.759707</td>\n",
       "      <td>-0.759707</td>\n",
       "      <td>-0.759707</td>\n",
       "      <td>-1.191513</td>\n",
       "      <td>1.385577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189418</td>\n",
       "      <td>-0.095515</td>\n",
       "      <td>-0.323572</td>\n",
       "      <td>0.340793</td>\n",
       "      <td>-0.020740</td>\n",
       "      <td>0.080697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.024416</td>\n",
       "      <td>-0.327865</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>0.523017</td>\n",
       "      <td>0.523017</td>\n",
       "      <td>0.523017</td>\n",
       "      <td>0.523017</td>\n",
       "      <td>0.523017</td>\n",
       "      <td>-0.449581</td>\n",
       "      <td>-0.538367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676050</td>\n",
       "      <td>-0.084086</td>\n",
       "      <td>-0.316806</td>\n",
       "      <td>-0.034659</td>\n",
       "      <td>-0.134766</td>\n",
       "      <td>-0.176524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.252270</td>\n",
       "      <td>-0.277816</td>\n",
       "      <td>-0.302264</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>-0.113516</td>\n",
       "      <td>0.165321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724556</td>\n",
       "      <td>1.334451</td>\n",
       "      <td>1.060225</td>\n",
       "      <td>0.548788</td>\n",
       "      <td>1.154545</td>\n",
       "      <td>0.904202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.176861</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>0.244690</td>\n",
       "      <td>-0.633745</td>\n",
       "      <td>-0.592400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.695864</td>\n",
       "      <td>-0.538563</td>\n",
       "      <td>-0.532487</td>\n",
       "      <td>-0.521544</td>\n",
       "      <td>-0.545716</td>\n",
       "      <td>-0.524931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.255416</td>\n",
       "      <td>-0.478013</td>\n",
       "      <td>0.091315</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.208386</td>\n",
       "      <td>0.717946</td>\n",
       "      <td>0.795223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871734</td>\n",
       "      <td>-0.859244</td>\n",
       "      <td>-0.618823</td>\n",
       "      <td>-0.852748</td>\n",
       "      <td>-0.874526</td>\n",
       "      <td>-0.857100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DaysInMilk__sum_values  DaysInMilk__minimum  Age__sum_values  \\\n",
       "id                                                                  \n",
       "32                -0.110237            -0.528062         0.333358   \n",
       "83                 0.055223            -0.377914         0.471188   \n",
       "95                 0.448078            -0.427963         1.156090   \n",
       "93                 0.243570             0.623070         0.528448   \n",
       "97                -0.169675            -0.478013         0.239230   \n",
       "81                -0.132798            -0.478013         0.118615   \n",
       "112               -0.147576            -0.478013         0.101769   \n",
       "94                -0.929461            -0.277816        -1.327105   \n",
       "59                -0.213278            -0.478013        -0.024831   \n",
       "6                 -0.234509            -0.077619        -0.402192   \n",
       "36                -0.102808            -0.478013         0.100144   \n",
       "18                 0.005303            -0.377914         0.431217   \n",
       "114                0.117454             1.273710        -0.419148   \n",
       "89                -0.809067            -0.327865        -1.155215   \n",
       "17                -0.017718            -0.277816         0.661475   \n",
       "19                -0.851150             0.022480        -1.173058   \n",
       "44                -0.927048             0.072529        -1.509302   \n",
       "84                -0.102835            -0.427963         0.285814   \n",
       "8                  0.216020             0.322775         0.290838   \n",
       "41                 1.524251             5.177550         1.173674   \n",
       "49                -0.518873            -0.528062        -0.478587   \n",
       "31                 0.418494            -0.478013         0.762216   \n",
       "63                -0.890523            -0.528062        -1.085727   \n",
       "38                 4.263194             1.774203         3.089442   \n",
       "71                -0.741521            -0.528062        -0.718303   \n",
       "56                 0.378932            -0.377914        -0.050838   \n",
       "96                -0.024416            -0.327865         0.096339   \n",
       "62                -0.252270            -0.277816        -0.302264   \n",
       "67                -0.176861            -0.478013        -0.000006   \n",
       "26                -0.255416            -0.478013         0.091315   \n",
       "\n",
       "     Age__length  DaysInMilk__length  mean_Total_timeDelta_Seconds__length  \\\n",
       "id                                                                           \n",
       "32      0.462511            0.462511                              0.462511   \n",
       "83      0.656129            0.656129                              0.656129   \n",
       "95      1.236986            1.236986                              1.236986   \n",
       "93      0.644028            0.644028                              0.644028   \n",
       "97      0.353600            0.353600                              0.353600   \n",
       "81      0.414106            0.414106                              0.414106   \n",
       "112     0.389904            0.389904                              0.389904   \n",
       "94     -1.497879           -1.497879                             -1.497879   \n",
       "59      0.268892            0.268892                              0.268892   \n",
       "6      -0.420875           -0.420875                             -0.420875   \n",
       "36      0.462511            0.462511                              0.462511   \n",
       "18      0.595624            0.595624                              0.595624   \n",
       "114    -0.832314           -0.832314                             -0.832314   \n",
       "89     -1.050135           -1.050135                             -1.050135   \n",
       "17      0.547219            0.547219                              0.547219   \n",
       "19     -1.292159           -1.292159                             -1.292159   \n",
       "44     -1.764104           -1.764104                             -1.764104   \n",
       "84      0.450410            0.450410                              0.450410   \n",
       "8       0.244690            0.244690                              0.244690   \n",
       "41      0.559320            0.559320                              0.559320   \n",
       "49     -0.275661           -0.275661                             -0.275661   \n",
       "31      1.128075            1.128075                              1.128075   \n",
       "63     -1.207450           -1.207450                             -1.207450   \n",
       "38      2.604418            2.604418                              2.604418   \n",
       "71     -0.783910           -0.783910                             -0.783910   \n",
       "56     -0.759707           -0.759707                             -0.759707   \n",
       "96      0.523017            0.523017                              0.523017   \n",
       "62      0.002666            0.002666                              0.002666   \n",
       "67      0.244690            0.244690                              0.244690   \n",
       "26      0.208386            0.208386                              0.208386   \n",
       "\n",
       "     milking_times__length  Total_MilkProduction__length  \\\n",
       "id                                                         \n",
       "32                0.462511                      0.462511   \n",
       "83                0.656129                      0.656129   \n",
       "95                1.236986                      1.236986   \n",
       "93                0.644028                      0.644028   \n",
       "97                0.353600                      0.353600   \n",
       "81                0.414106                      0.414106   \n",
       "112               0.389904                      0.389904   \n",
       "94               -1.497879                     -1.497879   \n",
       "59                0.268892                      0.268892   \n",
       "6                -0.420875                     -0.420875   \n",
       "36                0.462511                      0.462511   \n",
       "18                0.595624                      0.595624   \n",
       "114              -0.832314                     -0.832314   \n",
       "89               -1.050135                     -1.050135   \n",
       "17                0.547219                      0.547219   \n",
       "19               -1.292159                     -1.292159   \n",
       "44               -1.764104                     -1.764104   \n",
       "84                0.450410                      0.450410   \n",
       "8                 0.244690                      0.244690   \n",
       "41                0.559320                      0.559320   \n",
       "49               -0.275661                     -0.275661   \n",
       "31                1.128075                      1.128075   \n",
       "63               -1.207450                     -1.207450   \n",
       "38                2.604418                      2.604418   \n",
       "71               -0.783910                     -0.783910   \n",
       "56               -0.759707                     -0.759707   \n",
       "96                0.523017                      0.523017   \n",
       "62                0.002666                      0.002666   \n",
       "67                0.244690                      0.244690   \n",
       "26                0.208386                      0.208386   \n",
       "\n",
       "     Total_MilkProduction__sum_values  milking_times__variance  ...  \\\n",
       "id                                                              ...   \n",
       "32                           0.501672                -0.548284  ...   \n",
       "83                           1.070130                -0.594408  ...   \n",
       "95                           2.250353                 0.635476  ...   \n",
       "93                           0.843482                -0.209938  ...   \n",
       "97                           0.664145                 0.057348  ...   \n",
       "81                           0.620467                 0.520128  ...   \n",
       "112                          0.600703                 1.946572  ...   \n",
       "94                          -1.573042                -0.519888  ...   \n",
       "59                          -0.163308                 2.285260  ...   \n",
       "6                            0.111686                -0.361969  ...   \n",
       "36                           1.337947                 2.114234  ...   \n",
       "18                           0.816906                -0.065255  ...   \n",
       "114                         -1.376489                -0.371229  ...   \n",
       "89                          -1.051426                -0.671042  ...   \n",
       "17                           1.088563                 0.033272  ...   \n",
       "19                          -1.485384                -0.758146  ...   \n",
       "44                          -1.229845                 1.804892  ...   \n",
       "84                           0.634966                 1.842604  ...   \n",
       "8                            0.308734                 2.746202  ...   \n",
       "41                          -0.787655                -0.847223  ...   \n",
       "49                           0.210789                 1.371108  ...   \n",
       "31                           1.234561                 0.900149  ...   \n",
       "63                          -0.588661                -0.063863  ...   \n",
       "38                           2.284615                -1.216847  ...   \n",
       "71                          -0.264939                -0.598840  ...   \n",
       "56                          -1.191513                 1.385577  ...   \n",
       "96                          -0.449581                -0.538367  ...   \n",
       "62                          -0.113516                 0.165321  ...   \n",
       "67                          -0.633745                -0.592400  ...   \n",
       "26                           0.717946                 0.795223  ...   \n",
       "\n",
       "     mean_Total_timeDelta_Seconds__absolute_maximum  \\\n",
       "id                                                    \n",
       "32                                        -1.041292   \n",
       "83                                         2.509894   \n",
       "95                                         0.532950   \n",
       "93                                        -0.646198   \n",
       "97                                        -0.945139   \n",
       "81                                        -0.934918   \n",
       "112                                       -0.973999   \n",
       "94                                         2.345705   \n",
       "59                                        -0.902643   \n",
       "6                                         -0.817240   \n",
       "36                                        -0.720097   \n",
       "18                                         0.334885   \n",
       "114                                       -0.544416   \n",
       "89                                         1.021667   \n",
       "17                                         0.725999   \n",
       "19                                         1.599719   \n",
       "44                                        -0.289513   \n",
       "84                                        -0.834431   \n",
       "8                                         -0.960752   \n",
       "41                                         0.717027   \n",
       "49                                        -0.690000   \n",
       "31                                        -0.806030   \n",
       "63                                        -0.482174   \n",
       "38                                         0.058505   \n",
       "71                                        -0.705108   \n",
       "56                                         0.189418   \n",
       "96                                         0.676050   \n",
       "62                                         1.724556   \n",
       "67                                        -0.695864   \n",
       "26                                        -0.871734   \n",
       "\n",
       "     mean_Total_timeDelta_Seconds__standard_deviation  \\\n",
       "id                                                      \n",
       "32                                          -1.025806   \n",
       "83                                           1.696769   \n",
       "95                                           0.176336   \n",
       "93                                          -0.700438   \n",
       "97                                          -0.912552   \n",
       "81                                          -0.861258   \n",
       "112                                         -0.969377   \n",
       "94                                           2.587185   \n",
       "59                                          -0.831281   \n",
       "6                                           -0.818229   \n",
       "36                                          -0.604393   \n",
       "18                                           0.185630   \n",
       "114                                         -0.693198   \n",
       "89                                           1.834131   \n",
       "17                                          -0.132130   \n",
       "19                                           3.465402   \n",
       "44                                          -0.028211   \n",
       "84                                          -0.840283   \n",
       "8                                           -0.856261   \n",
       "41                                           0.506491   \n",
       "49                                          -0.525083   \n",
       "31                                          -0.847836   \n",
       "63                                          -0.393157   \n",
       "38                                           0.170602   \n",
       "71                                          -0.627169   \n",
       "56                                          -0.095515   \n",
       "96                                          -0.084086   \n",
       "62                                           1.334451   \n",
       "67                                          -0.538563   \n",
       "26                                          -0.859244   \n",
       "\n",
       "     mean_Total_timeDelta_Seconds__variance  \\\n",
       "id                                            \n",
       "32                                -0.642167   \n",
       "83                                 1.582869   \n",
       "95                                -0.143899   \n",
       "93                                -0.582878   \n",
       "97                                -0.627894   \n",
       "81                                -0.619193   \n",
       "112                               -0.635905   \n",
       "94                                 3.162783   \n",
       "59                                -0.613463   \n",
       "6                                 -0.610819   \n",
       "36                                -0.554655   \n",
       "18                                -0.137064   \n",
       "114                               -0.580921   \n",
       "89                                 1.799196   \n",
       "17                                -0.344779   \n",
       "19                                 5.132512   \n",
       "44                                -0.282736   \n",
       "84                                -0.615234   \n",
       "8                                 -0.618271   \n",
       "41                                 0.126959   \n",
       "49                                -0.527665   \n",
       "31                                -0.616686   \n",
       "63                                -0.475387   \n",
       "38                                -0.148093   \n",
       "71                                -0.561790   \n",
       "56                                -0.323572   \n",
       "96                                -0.316806   \n",
       "62                                 1.060225   \n",
       "67                                -0.532487   \n",
       "26                                -0.618823   \n",
       "\n",
       "     mean_Total_timeDelta_Seconds__median  \\\n",
       "id                                          \n",
       "32                              -1.030430   \n",
       "83                               0.707281   \n",
       "95                               0.450596   \n",
       "93                              -0.747602   \n",
       "97                              -0.918114   \n",
       "81                              -0.900730   \n",
       "112                             -0.965852   \n",
       "94                               2.130044   \n",
       "59                              -0.893125   \n",
       "6                               -0.793643   \n",
       "36                              -0.184676   \n",
       "18                              -0.124362   \n",
       "114                             -0.631008   \n",
       "89                               1.912881   \n",
       "17                              -0.227376   \n",
       "19                               2.827777   \n",
       "44                              -0.253859   \n",
       "84                              -0.733003   \n",
       "8                               -0.521815   \n",
       "41                               0.521490   \n",
       "49                              -0.137638   \n",
       "31                              -0.682990   \n",
       "63                              -0.087490   \n",
       "38                               0.782656   \n",
       "71                              -0.266761   \n",
       "56                               0.340793   \n",
       "96                              -0.034659   \n",
       "62                               0.548788   \n",
       "67                              -0.521544   \n",
       "26                              -0.852748   \n",
       "\n",
       "     mean_Total_timeDelta_Seconds__root_mean_square  \\\n",
       "id                                                    \n",
       "32                                        -1.058140   \n",
       "83                                         1.412190   \n",
       "95                                         0.209832   \n",
       "93                                        -0.733155   \n",
       "97                                        -0.942865   \n",
       "81                                        -0.895698   \n",
       "112                                       -1.001006   \n",
       "94                                         2.561090   \n",
       "59                                        -0.871022   \n",
       "6                                         -0.835462   \n",
       "36                                        -0.521655   \n",
       "18                                         0.105718   \n",
       "114                                       -0.712217   \n",
       "89                                         2.086804   \n",
       "17                                        -0.194232   \n",
       "19                                         3.566510   \n",
       "44                                        -0.083263   \n",
       "84                                        -0.832581   \n",
       "8                                         -0.789429   \n",
       "41                                         0.556243   \n",
       "49                                        -0.438222   \n",
       "31                                        -0.832080   \n",
       "63                                        -0.352834   \n",
       "38                                         0.343251   \n",
       "71                                        -0.543975   \n",
       "56                                        -0.020740   \n",
       "96                                        -0.134766   \n",
       "62                                         1.154545   \n",
       "67                                        -0.545716   \n",
       "26                                        -0.874526   \n",
       "\n",
       "     mean_Total_timeDelta_Seconds__mean  BreedName_1  BreedName_2  \\\n",
       "id                                                                  \n",
       "32                            -1.056369          0.0          1.0   \n",
       "83                             0.996408          0.0          0.0   \n",
       "95                             0.262504          0.0          1.0   \n",
       "93                            -0.738422          0.0          1.0   \n",
       "97                            -0.940886          0.0          1.0   \n",
       "81                            -0.899492          0.0          1.0   \n",
       "112                           -0.999429          1.0          0.0   \n",
       "94                             2.488318          0.0          0.0   \n",
       "59                            -0.881779          1.0          0.0   \n",
       "6                             -0.820762          0.0          1.0   \n",
       "36                            -0.410717          0.0          1.0   \n",
       "18                             0.019451          0.0          1.0   \n",
       "114                           -0.701781          0.0          1.0   \n",
       "89                             2.348882          0.0          1.0   \n",
       "17                            -0.249650          1.0          0.0   \n",
       "19                             3.628231          1.0          0.0   \n",
       "44                            -0.131920          0.0          1.0   \n",
       "84                            -0.792078          1.0          0.0   \n",
       "8                             -0.696952          0.0          1.0   \n",
       "41                             0.620812          0.0          0.0   \n",
       "49                            -0.322960          0.0          1.0   \n",
       "31                            -0.783870          1.0          0.0   \n",
       "63                            -0.283444          0.0          1.0   \n",
       "38                             0.539902          0.0          1.0   \n",
       "71                            -0.432866          1.0          0.0   \n",
       "56                             0.080697          0.0          0.0   \n",
       "96                            -0.176524          0.0          0.0   \n",
       "62                             0.904202          0.0          0.0   \n",
       "67                            -0.524931          0.0          1.0   \n",
       "26                            -0.857100          0.0          1.0   \n",
       "\n",
       "     BreedName_4  BreedName_99  \n",
       "id                              \n",
       "32           0.0           0.0  \n",
       "83           0.0           1.0  \n",
       "95           0.0           0.0  \n",
       "93           0.0           0.0  \n",
       "97           0.0           0.0  \n",
       "81           0.0           0.0  \n",
       "112          0.0           0.0  \n",
       "94           1.0           0.0  \n",
       "59           0.0           0.0  \n",
       "6            0.0           0.0  \n",
       "36           0.0           0.0  \n",
       "18           0.0           0.0  \n",
       "114          0.0           0.0  \n",
       "89           0.0           0.0  \n",
       "17           0.0           0.0  \n",
       "19           0.0           0.0  \n",
       "44           0.0           0.0  \n",
       "84           0.0           0.0  \n",
       "8            0.0           0.0  \n",
       "41           1.0           0.0  \n",
       "49           0.0           0.0  \n",
       "31           0.0           0.0  \n",
       "63           0.0           0.0  \n",
       "38           0.0           0.0  \n",
       "71           0.0           0.0  \n",
       "56           0.0           1.0  \n",
       "96           1.0           0.0  \n",
       "62           0.0           1.0  \n",
       "67           0.0           0.0  \n",
       "26           0.0           0.0  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03520281, 0.96479719],\n",
       "       [0.91692691, 0.08307309],\n",
       "       [0.82610546, 0.17389454],\n",
       "       [0.14017063, 0.85982937],\n",
       "       [0.02178738, 0.97821262],\n",
       "       [0.02642363, 0.97357637],\n",
       "       [0.03681407, 0.96318593],\n",
       "       [0.93542667, 0.06457333],\n",
       "       [0.06347022, 0.93652978],\n",
       "       [0.1087162 , 0.8912838 ],\n",
       "       [0.22060036, 0.77939964],\n",
       "       [0.78781165, 0.21218835],\n",
       "       [0.30398658, 0.69601342],\n",
       "       [0.96433078, 0.03566922],\n",
       "       [0.72401821, 0.27598179],\n",
       "       [0.91192938, 0.08807062],\n",
       "       [0.502272  , 0.497728  ],\n",
       "       [0.04156812, 0.95843188],\n",
       "       [0.13429596, 0.86570404],\n",
       "       [0.59287503, 0.40712497],\n",
       "       [0.12107734, 0.87892266],\n",
       "       [0.0835192 , 0.9164808 ],\n",
       "       [0.60982533, 0.39017467],\n",
       "       [0.63018764, 0.36981236],\n",
       "       [0.54626235, 0.45373765],\n",
       "       [0.57491024, 0.42508976],\n",
       "       [0.76781719, 0.23218281],\n",
       "       [0.93766834, 0.06233166],\n",
       "       [0.39676838, 0.60323162],\n",
       "       [0.02782847, 0.97217153]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = model.predict_proba(X_test)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['32', '83', '95', '93', '97', '81', '112', '94', '59', '6', '36', '18',\n",
       "       '114', '89', '17', '19', '44', '84', '8', '41', '49', '31', '63', '38',\n",
       "       '71', '56', '96', '62', '67', '26'],\n",
       "      dtype='object', name='id')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cow_id = X_test.index.copy()\n",
    "cow_id = cow_id.astype(str)\n",
    "cow_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "font_color = '#525252'\n",
    "hfont = {'fontname':'Calibri'}\n",
    "facecolor = '#eaeaf2'\n",
    "color_red = '#f44336'\n",
    "color_blue = '#4496df'\n",
    "index = cow_id\n",
    "column0 = prob_list[:, 0]\n",
    "column1 = prob_list[:, 1]\n",
    "title0 = 'Slow learner, test set'\n",
    "title1 = 'Fast learner, test set'\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,5), facecolor=facecolor, ncols=2, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "axes[0].barh(index, column0, align='center', color=color_red, zorder=10)\n",
    "axes[0].set_title(title0, fontsize=18, pad=15, color=color_red, **hfont)\n",
    "axes[1].barh(index, column1, align='center', color=color_blue, zorder=10)\n",
    "axes[1].set_title(title1, fontsize=18, pad=15, color=color_blue, **hfont)\n",
    "\n",
    "# If you have positive numbers and want to invert the x-axis of the left plot\n",
    "axes[0].invert_xaxis() \n",
    "\n",
    "# To show data from highest to lowest\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "axes[0].set(yticks=cow_id, yticklabels=cow_id)\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[0].tick_params(axis='y', colors='black') # tick color\n",
    "\n",
    "axes[0].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[0].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "axes[1].set_xticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "\n",
    "for label in (axes[0].get_xticklabels() + axes[0].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "for label in (axes[1].get_xticklabels() + axes[1].get_yticklabels()):\n",
    "    label.set(fontsize=13, color=font_color, **hfont)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, top=0.85, bottom=0.1, left=0.18, right=0.95)\n",
    "filename = 'good&bad_learner'\n",
    "plt.savefig(filename+'.png', facecolor=facecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'GPC-Matern-Test'),\n",
       " Text(0.5, 0, 'Predicted probability(positive class)'),\n",
       " Text(0, 0.5, 'Count')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEXCAYAAACjyo8UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmaElEQVR4nO3deVRU5f8H8PcMiGSDoohY6SHBrczMtMyFFHeQTdDCDdTc0kwpF1xQlDBDU1PTo+U3DVdMcak0t8gF1zSXVKwMAjFBFBgEBGae3x8e70+EgQHmMnF5v87xHObO3Pl8nrnjm8udO89VCSEEiIhIsdTmboCIiOTFoCciUjgGPRGRwjHoiYgUjkFPRKRwDHoiIoWzNHcDVL1t374dUVFRyMrKQn5+Pho3bozJkyejTZs2GDZsGG7dugUbGxuoVCrk5+fjlVdeQWhoKJ555hkAwM8//4z//e9/0Gq1yM/PR7NmzTB9+nQ899xzRWqdPn0aAQEB8Pb2RkRERKH7hg0bhitXruDChQsl9hsTE4OLFy9i0qRJpnsRnrBr1y588803AIDbt2+jZs2aqFevHgAgJCQE7du3N/q5tFotJkyYgG+//VaWXqnqYNCT2SxZsgRnz57FsmXL8MILLwAATp48ibFjx2Lnzp0AgGnTpqFv374AACEEJk2ahOXLl2P69OnYu3cvVq9ejdWrV8PR0RFCCKxduxYBAQH44YcfYGVlVaSmvb09YmJikJOTI/2yuHXrFv7++2+jer58+TIyMjJMMfxi+fj4wMfHBwAQHByMZs2a4b333ivXc2VkZODy5csm7I6qKgY9mcXdu3exYcMGHDx4EA0aNJCWd+zYEcHBwcjJySmyjkqlQocOHXD06FEAwNKlSxEWFgZHR0fp/jFjxuD5559HXl5esUFva2uLxo0b49ChQ/D09ATwaC/a09MTW7duBQBkZ2cjNDQU8fHxyMjIwLPPPovFixdDq9Vi69at0Ol0sLGxQVBQELZv344tW7ZAr9fD1tYWISEhcHZ2RnBwMNLT05GYmIhu3bohLS0NGo0GcXFx+Pfff+Hk5IQlS5bg2WefNfo1O3/+PBYvXoycnByoVCpMnDgRrq6uSE1NxfTp03H//n0AQNeuXTF58mTMmDEDubm58Pb2xs6dO2FhYWF0LVIWHqMns/jtt9/g7OxcKOQf8/HxgbOzc5HlGRkZ2LdvHzp06ID79+/j1q1beP311ws9RqVSwdPTExqNxmBtHx8f7N69W7q9b98+eHh4SLePHj2K2rVrIyoqCj/99BNeeeUVbNq0CW3atIG/vz/c3d0RFBSEM2fOYNeuXdi0aRN27dqFUaNGYeLEidLz5Obm4ocffsDUqVMBAFeuXMG6devw448/IiUlBfv37zf69crIyMCMGTMQERGB6OhorF69GqGhoUhOTkZUVBQaNWqE6OhobNq0CQkJCdBqtfj0009hbW2N3bt3M+SrOe7Rk1k8PfNGVlYWhgwZAuDRHrWbmxsAICIiAqtXr5Ye7+rqioCAADx48AAAoNfry1zb1dUVoaGhSEtLQ3x8PJycnFCnTh3p/r59+6Jx48aIjIxEQkICzpw5g7Zt2xZ5npiYGCQkJMDf319alpGRgfT0dABAu3btCj3excVF+iujefPmZToE9NtvvyE1NRUTJkyQlqlUKsTFxcHFxQVjxozB7du30alTJ3z88cewsbGR9RATVS0MejKLV199FX///Tfu37+PunXrQqPRSHvZK1askA5DPHmM/kl16tTBiy++iIsXL6JTp06F7ps0aRLef/99REZG4sqVKwAAf39/ODk5AQCsrKzQu3dvfP/99/jzzz/Rv3//Qutv3rwZUVFRGDJkCDw9PWFra4ukpKQiPej1enh7e0t77Hq9HikpKdIvjVq1ahV6vLW1tfSzSqWCEAKHDx/G8uXLAQANGjTAV199VezrpdPp4OzsjO3bt0vL7ty5g3r16qFGjRo4fPgwTp48iVOnTmHgwIH48ssvi/1riaonHrohs3BwcEBAQAAmTZqE5ORkaXlycjLOnz8Ptbr0t+YHH3yA8PBwJCQkAHgUhqtWrcL169fh5OSE8PBw7N69G7t378agQYMKrevj44Po6GicPXsWLi4uhe47fvw4+vfvj4EDB6JJkyY4cuQIdDodAMDCwgIFBQUAgM6dO+OHH35ASkoKAGDLli0IDAws0+vQo0cPqUdDIQ8Ar732GhISEnD27FkAwLVr19CnTx+kpKRg8eLFWLVqFXr27IlZs2ahadOmiI+Ph6WlJXQ6XZG/nqj64R49mU1QUBD27NmDKVOmIDs7GwUFBbCysoK7uzuGDBmCMWPGlLi+p6cnhBD46KOPUFBQgIcPH6JVq1bYsGFDsR/EPqlt27bIyclB9+7dYWlZ+L/ByJEjMWfOHOkDzFatWuHGjRsAHn1YPHHiRNSoUQMhISEYPXo0Ro4cCZVKBY1Gg5UrV0KlUlXshSlGvXr1sHz5ckRERODhw4cQQiAiIgIvvPACAgMDERwcDA8PD1hZWaFFixbw8PCAhYUFXn75Zbi5uWHLli2oW7euyfuiqkHFaYqJiJSNh26IiBSOQU9EpHAMeiIihWPQExEpHIOeiEjhGPRERAr3nz2P/v79B9Dry37mp52dBmlpWTJ09N/FMVcPHHP1UN4xq9Uq1K1b/CR5/9mg1+tFuYL+8brVDcdcPXDM1YOpx8xDN0RECsegJyJSOAY9EZHCMeiJiBRO1qDfvXs3+vXrh379+uGzzz6TsxQRERkgW9Dn5OQgPDwckZGR2L17N86dO4fY2Fi5yhERkQGyBb1Op4Ner0dOTg4KCgpQUFCAmjVrylWOiIgMkHU++sjISCxatAjW1tZ48803sWLFClkuykBEZEr6vFyoraxLf2AVqS3bF6auX7+OHTt24Oeff4aNjQ2mTJmCdevWYdSoUUatn5aWVa4vDdjb2yA1VVvm9aoyjrl64Jgrt+6N4RaVXhcAmq/XlWvMarUKdnaa4u+raFOGHD9+HB07doSdnR2srKzg6+uLM2fOyFWOiIgMkC3oW7ZsidjYWGRnZ0MIgSNHjqB169ZylSMiIgNkO3TTpUsXXL16Fb6+vqhRowZat25d6sWeiYjI9GSd1GzMmDEMdyIiM+M3Y4mIFI5BT0SkcAx6IiKFY9ATESkcg56ISOEY9ERECsegJyJSOAY9EZHCMeiJiBSOQU9EpHAMeiIihWPQExEpHIOeiEjhGPRERArHoCciUjgGPRGRwsl24ZHt27dj48aN0u2kpCR4e3tjzpw5cpUkIqJiyBb0AwcOxMCBAwEAf/zxByZMmIAPPvhArnJERGRApRy6CQ0NRVBQEOrVq1cZ5YiI6AmyB31sbCxyc3Ph5uYmdykiIiqGrBcHB4CtW7dixIgRZV7Pzk5T7pr29jblXreq4pirB465ejD1mGUN+ry8PJw9exYLFy4s87ppaVnQ60WZ17O3t0FqqrbM61VlHHP1wDFXbl1zKs+Y1WqVwR1kWQ/dxMXF4cUXX0StWrXkLENERCWQNegTExPRsGFDOUsQEVEpZD104+7uDnd3dzlLEBFRKfjNWCIihWPQExEpHIOeiEjhGPRERArHoCciUjgGPRGRwjHoiYgUjkFPRKRwDHoiIoVj0BMRKRyDnohI4Rj0REQKx6AnIlI4Bj0RkcIx6ImIFI5BT0SkcAx6IiKFkzXojxw5Al9fX/Tt2xeffPKJnKWIiMgA2YI+MTERc+fOxapVq7B3715cvXoVv/zyi1zliIjIANmuGXvw4EG4u7tLFwdfunQpatasKVc5IiIyQLY9+oSEBOh0Orz33nvw8vLC5s2bUadOHbnKERGRAbLt0et0Opw7dw6RkZGoVasWxo8fj+joaPj6+hq1vp2dpty17e1tyr1uVcUxVw8cc/Vg6jHLFvT169dHx44dUa9ePQBAjx49cOnSJaODPi0tC3q9KHNde3sbpKZqy7xeVcYxVw8cc+XWNafyjFmtVhncQZbt0I2rqyuOHz+OzMxM6HQ6HDt2DK1atZKrHBERGSDbHn2bNm0watQoDB48GPn5+ejcuTP8/PzkKkdERAbIFvQAMGDAAAwYMEDOEkREVAp+M5aISOEY9ERECsegJyJSOAY9EZHCMeiJiBSOQU9EpHAMeiIihWPQExEpHIOeiEjhGPRERArHoCciUjgGPRGRwjHoiYgUjkFPRKRwDHoiIoVj0BMRKRyDnohI4WS9wlRAQADS0tJgafmozPz589GmTRs5SxIR0VNkC3ohBG7evImYmBgp6ImIqPLJdujm5s2bUKlUGD16NLy8vLBx40a5ShERUQlk29XOzMxEx44dERoaitzcXAQEBKBJkybo3LmzXCWJiKgYKiGEqIxC69evR3JyMmbOnClrHX1eLtRW1rLW+C/WJiLTujHcwix1m6/Xmfw5ZdujP3fuHPLz89GxY0cAj47Zl+VYfVpaFvT6sv8Osre3MesGSk3VVnpde3sbs9Q1J465ejDXmO3tbSq95pPKM2a1WgU7O03x91W0IUO0Wi0iIiLw8OFDZGVlITo6Gr169ZKrHBERGSDbHr2rqysuXrwIHx8f6PV6DB48GG3btpWrHBERGSDreY+TJ0/G5MmT5SxBRESl4DdjiYgUjkFPRKRwRgV9cadETpw40eTNEBGR6ZV4jH7u3Lm4c+cOfv31V9y7d09aXlBQgJs3b8reHBERVVyJQT9gwAD88ccfiIuLQ58+faTlFhYWPIOGiKiKKDHoW7dujdatW6NTp05o2LBhZfVEREQmZNTplf/88w+mTp2KjIwMPDljwt69e2VrjIiITMOooJ8/fz78/Pzw8ssvQ6VSyd0TERGZkFFBX6NGDYwYMULuXoiISAZGnV7ZrFkzxMXFyd0LERHJwKg9+sTERPj5+eH5559HzZo1peU8Rk9E9N9nVNAHBQXJ3QcREcnEqKBv3ry53H0QEZFMjAr6t956CyqVCkII6awbe3t7HD16VNbmiIio4owK+uvXr0s/5+fn48CBA4WWERHRf1eZZ6+sUaMG+vXrhxMnTsjRDxERmZhRe/Tp6enSz0IIXLlyBZmZmXL1REREJlTmY/QAYGdnh1mzZhlV4LPPPsP9+/excOHC8ndJRETlVuZj9GVx8uRJREdHo1u3buVan4iIKs6ooNfr9Vi3bh2OHj2KgoICdO7cGePGjYOlpeHV09PTsXTpUowbN44f3BIRmZFRH8Z+/vnnOHXqFAIDAzFixAhcuHABERERJa4zZ84cBAUFoXbt2iZplIiIyseoPfpjx45hx44dqFGjBgCgW7du8PLyKvYSgwCwfft2PPfcc+jYsSN27txZrsbs7DTlWs/c7O1tqlVdc9Hn5ZplzPq8XKitrCu97mPcztWDqcdsVNALIaSQBwArK6tCt5/2448/IjU1Fd7e3sjIyEB2djYWLFhg8BdDcdLSsqDXi9If+BRzvylSU7WVXtPe3sYsdc3J3t4GN4ZbVHrd5ut1ZnutuZ0rT/P1ukqv+aTybGe1WmVwB9mooG/ZsiUWLFiAoUOHAgA2btxY4rQI33zzjfTzzp07cebMmTKFPBERmY5Rx+jnzp2LzMxM+Pv745133sH9+/cREhIid29ERGQCJe7R5+XlISQkBL169ZLOgx8zZgwsLCyg0Rh3DN3X1xe+vr4V75SIiMqlxD365cuXIysrC23btpWWhYWFITMzEytWrJC9OSIiqrgSgz4mJgaff/457OzspGUODg6IiIjAoUOHZG+OiIgqrsSgr1GjBqyti55KptFoYGVlJVtTRERkOiUGvVqtRlZWVpHlWVlZKCgokK0pIiIynRKD3sPDA7Nnz0Z2dra0LDs7G7Nnz0bv3r1lb46IiCquxKAPDAyEjY0NOnfujHfeeQcDBgxA586dUbt2bUyYMKGyeiQiogoo8fRKtVqNsLAwjB07FlevXoVarUbr1q3h4OBQWf0REVEFGfXN2EaNGqFRo0Zy90JERDIo86UEiYioamHQExEpHIOeiEjhGPRERArHoCciUjgGPRGRwjHoiYgUjkFPRKRwDHoiIoWTNei/+OILuLu7o1+/foWuI0tERJXHqCkQyuPMmTM4deoU9uzZg4KCAri7u6Nr165wcnKSqyQRERVDtj36N998E99++y0sLS2RlpYGnU6HWrVqyVWOiIgMkPXQTY0aNbB8+XL069cPHTt25KyXRERmINuhm8c+/PBDjB49GuPGjUNUVBTeffddo9azs9PI3Jk87O1tKr2mPi/XbHXVVkUvNal05nit/wu1qfKYejvLFvR//fUX8vLy8NJLL+GZZ55B7969ERcXZ/T6aWlZ0OtFmeua+z9Caqq20mva29vgxnCLSq/bfL3OLOMFzLudzTlmc9U2F3P/fzaX8mxntVplcAdZtkM3SUlJmD17NvLy8pCXl4fDhw+jXbt2cpUjIiIDZNuj79q1Ky5evAgfHx9YWFigd+/e6Nevn1zliIjIAFmP0X/44Yf48MMP5SxBRESl4DdjiYgUjkFPRKRwDHoiIoVj0BMRKRyDnohI4Rj0REQKx6AnIlI4Bj0RkcIx6ImIFI5BT0SkcAx6IiKFY9ATESkcg56ISOEY9ERECsegJyJSOAY9EZHCMeiJiBRO1itMrVy5Evv27QPw6NKC06ZNk7McEREVQ7Y9+tjYWBw/fhzR0dHYtWsXfv/9dxw8eFCuckREZIBse/T29vYIDg6GlZUVAMDZ2RnJyclylSMiIgNkC/pmzZpJP8fHx+PHH3/E1q1bjV7fzk4jR1uys7e3MXcLlUafl1utxvuYucZsrtdbn5cLtZV1pdetzky9nWU9Rg8Af/zxB8aOHYvp06fjxRdfNHq9tLQs6PWizPXMHTypqdpKr2muMautrHFjuIVZajdfrzNLXcA82xh4tJ3N8Xo3X68z65iro/K83mq1yuAOsqxn3fz6668YPnw4Pv74Y/Tv31/OUkREZIBse/S3b9/GhAkTsHTpUnTs2FGuMkREVArZgn7dunV4+PAhFi5cKC3z9/fHoEGD5CpJRETFkC3oZ8+ejdmzZ8v19EREZCR+M5aISOEY9ERECsegJyJSOAY9EZHCMeiJiBSOQU9EpHAMeiIihWPQExEpHIOeiEjhGPRERArHoCciUjgGPRGRwjHoiYgUjkFPRKRwDHoiIoVj0BMRKRyDnohI4WQP+qysLHh4eCApKUnuUkREVAxZg/7ixYsYNGgQ4uPj5SxDREQlkDXoo6KiMHfuXDRo0EDOMkREVALZLg4OAOHh4eVe185OY8JOKoc+Lxf29jbmboNkVt22Md/Xlc/Ur7esQV8RaWlZ0OtFmdcz5xtSbWWNG8MtKr1u8/W6Sq9ZnaWmas1S11zvbXO9r4Hq+94uz3tMrVYZ3EHmWTdERArHoCciUjgGPRGRwlXKMfojR45URhkiIioG9+iJiBSOQU9EpHAMeiIihWPQExEpHIOeiEjhGPRERArHoCciUjgGPRGRwjHoiYgUjkFPRKRwDHoiIoVj0BMRKRyDnohI4Rj0REQKx6AnIlI4Bj0RkcIx6ImIFE7WoN+7dy/c3d3Rq1cvbNq0Sc5SRERkgGyXErxz5w6WLl2KnTt3wsrKCv7+/ujQoQOaNm0qV0kiIiqGbEEfGxuLt956C7a2tgCAPn36YP/+/fjggw+MWl+tVpW7tmV9x3KvW1Hmql3d6pqzdkXemxXF7az8ukD53mMlraMSQoiKNGTImjVrkJ2djaCgIADA9u3bcenSJYSFhclRjoiIDJDtGH1xvz9UKvPtCRERVVeyBb2DgwPu3r0r3U5JSUGDBg3kKkdERAbIFvSdOnXCyZMnce/ePeTk5ODAgQN4++235SpHREQGyPZhrIODA4KCghAQEID8/HwMGDAAr776qlzliIjIANk+jCUiov8GfjOWiEjhGPRERArHoCciUjgGPRGRwlXZoC9twrRr167Bz88Pffr0waxZs1BQUGCGLk2rtDEfOnQI3t7e8PLywvjx45GRkWGGLk3L2InxYmJi0L1790rsTD6ljfnmzZsYNmwYvLy88N5771X57VzaeH///Xf4+fnBy8sLY8eORWZmphm6NL2srCx4eHggKSmpyH0mzy9RBf3777/C1dVV3L9/Xzx48EB4enqKP/74o9Bj+vXrJy5cuCCEEGLGjBli06ZNZujUdEobs1arFZ07dxb//vuvEEKIZcuWibCwMHO1axLGbGchhEhNTRV9+/YVrq6uZujStEobs16vF7179xa//PKLEEKIRYsWiYiICHO1W2HGbONBgwaJmJgYIYQQn376qViyZIk5WjWp3377TXh4eIhWrVqJxMTEIvebOr+q5B79kxOm1apVS5ow7bFbt24hNzcXr732GgDA19e30P1VUWljzs/PR2hoKBwcHAAALVq0wO3bt83VrkmUNubHZs+ebfRkef91pY35999/R61ataQvH44bNw5DhgwxV7sVZsw21uv1ePDgAQAgJycH1tbW5mjVpKKiojB37txiZwuQI7+qZNCnpKTA3t5eut2gQQPcuXPH4P329vaF7q+KShtz3bp10bNnTwBAbm4u1q5dK92uqkobMwB8++23ePnll9GmTZvKbk8WpY35n3/+Qf369TF9+nR4enpi7ty5qFWrljlaNQljtnFwcDBmzZqFLl26IDY2Fv7+/pXdpsmFh4ejffv2xd4nR35VyaAXpUyYVtr9VZGxY9JqtRg9ejRatmyJ/v37V0ZrsiltzDdu3MCBAwcwfvz4ymxLVqWNuaCgAGfOnMHQoUOxd+9eNG7cGAsXLqzMFk2qtPHm5uZi1qxZ2LBhA44fP47Bgwdj+vTpldlipZMjv6pk0Jc2YdrT96emplb5CdWMmSQuJSUFgwcPRsuWLREeHl7ZLZpcaWPev38/UlNT4efnhzFjxkjjr8pKG7O9vT0cHR3RunVrAICHhwcuXbpU6X2aSmnjvXHjBmrWrClNn/Luu+/izJkzld5nZZIjv6pk0Jc2YdoLL7yAmjVr4tdffwUA7Nq1q8pPqFbamHU6HcaNGwc3NzfMmjWryv8FA5Q+5g8//BA//fQTdu/ejbVr16JBgwbYvHmzGTuuuNLG3LZtW9y7dw/Xr18HABw5cgStWrUyV7sVVtp4HR0d8e+//+LmzZsAgMOHD0u/5JRKlvyq0Ee5ZrRnzx7Rr18/0bt3b7F27VohhBCjRo0Sly5dEkIIce3aNeHn5yf69u0rPvroI/Hw4UNztmsSJY35wIEDokWLFsLLy0v6N3PmTDN3XHGlbefHEhMTFXHWjRClj/m3334Tfn5+wt3dXYwcOVLcvXvXnO1WWGnjjYmJEZ6ensLDw0MEBgaKf/75x5ztmpSrq6t01o2c+cVJzYiIFK5KHrohIiLjMeiJiBSOQU9EpHAMeiIihWPQExEpHIO+CktKSsJLL70Eb29v6Z+Xlxe+++67Cj/32LFjsXPnTgCAt7d3iTMGarVaBAQElLnG/v37MWzYsHL3WJoWLVrg3r17ZVpn2LBhxc4rcufOHemr9ytWrMD8+fMBAKNHj8aff/4JABg5cqRR9a5du4YZM2aUqS9jfPHFF9i1axcAYOXKlTh06FCR5XLp3r07Ll++bNLnPHToEFauXGnS56yuZLs4OFUOa2tr7N69W7p9584deHh44JVXXkHLli1NUuPJ5y9ORkaGyf+T/9c4ODhg69atRZZ/9dVX0s8nTpwo9Xn0ej1mzZqF1atXm7Q/AJg0aZL08+nTp9G0adMiy6uSnj17YtOmTbh27Rpeeuklc7dTpTHoFcbBwQGOjo6Ij4/H1atX8d133yEnJwcajQaRkZHYvn07tmzZAr1eD1tbW4SEhMDZ2Rl37txBcHAwUlJS8PzzzyMtLU16zhYtWuDkyZOoV68e1qxZg+joaFhaWsLR0RELFy7EjBkzkJubC29vb+zcuRPx8fEIDw9Heno6dDodhg0bhgEDBgB4tHe5d+9e2NrawtHRsdgxnD59GhEREXBwcEBiYiKsra2xcOFCODs7Izg4GOnp6UhMTES3bt0wbtw4zJs3D9evX4dKpYKLiws++ugjWFo+emsvW7YMly9fhl6vx+TJk+Hq6ors7GyEhoYiPj4eGRkZePbZZ7F48WI4OTkBAA4ePIi1a9ciNzcXnp6eeP/995GUlARPT09cuHChUK/du3fHF198IX0jNzAwECEhIZg6dSp+/vlnqNVq5OTkoHv37vj+++9x6tQpNGrUSJpltHv37ujZsyfOnTsHrVaLESNGSNM4bNu2DZGRkVCr1ahfvz5CQkLQpEkTnDt3DgsXLoRerwfw6K+vPn36IDg4GM2aNYO1tTWuXLmCiIgIWFhY4PDhw2jWrBk0Gg2OHDmCNWvWAAD++usvDB8+HDExMSVusyf9/fffmDNnDu7duwe1Wo33338f7u7u0v16vR4LFizAxYsX8eDBAwgh8Mknn6Bdu3YG+za0HAAGDBiAlStX4ssvvzTuPwAVr2Lf6yJzSkxMFK+99lqhZefPnxdvvPGGSE5OFjt27BBvvPGG0Gq1QgghTp8+LQYPHiyys7OFEEIcO3ZMuLm5CSGEGD9+vFi6dKkQQoj4+Hjx2muviR07dgghhGjevLlIS0sThw4dEr179xbp6elCCCEWLFggVq1aVaiP/Px84e7uLq5cuSKEECIzM1O4ubmJCxcuiIMHDwp3d3eh1WpFfn6+GDNmjBg6dGiRcZ06dUq0bNlSnD17VgghxObNm0X//v2FEEJMnz5dBAYGSo+dNm2aCAsLE3q9Xjx8+FCMHDlSrFmzRur78c9xcXHizTffFGlpaWLfvn2F5uoPCQkR8+fPF0IIMXToUDF27FiRn58vtFqt6Nu3r4iJiSk0xuXLl4t58+YJIR59s/Hxtxkfv05CCOHl5SXNob59+3YRFBQkhBBi4sSJ0uv6eP2QkBCh1+vF7du3RYcOHcT169dFbGys6Nmzp/R8O3bsEG5ubkKv14uAgADx/fffCyEefYMyNDRUem2+/vpraRz79u0rtFyr1Yp27dqJlJQUIYQQERERYsmSJSVus6f5+PiIjRs3CiGESE5OFj169BBarVZ6Hc6fPy8mTpwodDqdEEKINWvWiLFjxwohhMG+DS0X4tF1Fl599VWRk5NTpBcyHvfoq7jHe9LAo/lu6tati0WLFuG5554D8GhvXKPRAHh0FaaEhIRC07xmZGQgPT0dsbGx0qyAjo6O6NChQ5FaJ0+eRN++fVGnTh0AkI4zP3mFnPj4ePzzzz+YOXNmoR6vXr2Kv/76C7169ZL68fPzQ2RkZLHjatmypTSNq5+fH+bPn4/79+8DANq1ayc97ujRo9iyZQtUKhWsrKzg7++PDRs2YMyYMQCAQYMGAQCaN28OZ2dnXLhwAX379kXjxo0RGRmJhIQEnDlzBm3btpWec8CAAbC0tIRGo0GfPn0QGxsLZ2fnkjZDEUOGDEFUVBS6du2Kbdu2Ydq0aQAeXR3q6c8zBg8eDJVKhYYNG8LFxQUnTpzA3bt34e7ujnr16gF4NCd5eHg4kpKS4Obmhvnz5+PIkSPo1KkTPvroI6N6ejyePXv2YPjw4dizZw82b95c4jZ7PCc6AKSnp+P69esYOHAgAOC5556TPgd4rG3btqhTpw62bt2KxMREnD59Gs8++ywAGOy7pPFoNBpoNBrcunWrzNuA/h+Dvop7+hj9056cq1yv18Pb2xtTp06VbqekpKBOnTpQqVSFpkd9fOjjSRYWFoUmS8vMzCzyIa1Op0Pt2rUL9XT37l3Y2Nhg0aJFhWpYWFgY7Pvp+4QQ0rKnx/QkvV5f6LJravX/n28ghIClpSU2b96MqKgoDBkyBJ6enrC1tS30y+rJ2o/XKStPT08sWbIEp06dQnZ2Nt544w0Aj6abfbrnJ59fr9dDrVYXO1WtEAIFBQXw9/eHq6srTpw4gWPHjmHlypXYs2ePUX0NHDhQOlzXtGlTNG7cGHFxcQa3WXF9PvkeuHnzJp5//nnpdkxMDMLDwzFixAj06NEDTk5OUm+G+ja0/HF9nU5X4nuFSsezbqqRzp0744cffkBKSgoAYMuWLQgMDAQAuLi4YNu2bQCA5ORknD59usj6nTp1wsGDB5GVlQXg0dkn69evh6WlJXQ6HYQQaNKkCWrWrCmFxu3bt+Hh4YErV67AxcUF+/fvR2ZmJvR6fYm/oK5fvy7N0Lht2za8/vrrqF27dpHHdenSBZs2bYIQAnl5eYiKikKnTp2k+6OjowE8ujJTQkIC2rRpg+PHj6N///4YOHAgmjRpgiNHjkCn00nr7Nq1C0IIZGRkYN++fUbPHGhhYSH9knnmmWfg5eWFmTNnFvoLqkmTJkhMTCy03uMzYpKTk3HixAm8/fbb6NKlC3788UfpLJ4dO3ZIn2v4+/vj2rVr8PX1RVhYGDIzM4tcN/bJXp70eA/9yy+/lPbMS9pmT9JoNGjVqpXU7+3btzFo0CBotVrpMSdOnICrqysGDx6M1q1b49ChQ9Jra6jvksaj1Wrx8OHDQr9MqOy4R1+NuLi4YPTo0Rg5ciRUKhU0Gg1WrlwJlUqFuXPnYsaMGXBzc0PDhg2LPWOna9eu+PPPP6XDIU2bNkVYWBieeeYZvPzyy3Bzc8OWLVuwatUqhIeH4+uvv0ZBQQEmTZokHW6Ji4uDn58fateujZYtW0qHY55Wv359LFu2DLdu3UK9evUQERFR7ONmz56NTz75BJ6ensjPz4eLiwvGjRsn3Z+YmAgfHx+oVCosWbIEtra2GDlyJObMmYOdO3fCwsICrVq1wo0bN6R1bGxs4Ovri9zcXAwdOhQdOnQo9gLOT+vVqxcGDx6MVatWoXnz5vD19UVUVBR8fHykx/Tp0wcHDx6En5+ftCwpKUmqN3v2bDg5OcHJyQnDhw9HYGAg9Hq99EG4Wq3GlClTsGDBAixbtgxqtRoffPABGjVqVKgXV1dXfPbZZ8jPzy/S58CBA7Fq1SrpCmRWVlYlbrMnff7555g3bx4iIyOhUqkQHh5e6GpI/v7+mDJlCjw9PWFhYYH27dvjwIED0Ov1BvsuaTzHjx9Ht27dYGVlVerrT4Zx9kr6zzl9+jTCwsLw/fffm7uVchNC4KuvvsKtW7cwb948ablOp4Ovry/Wrl0LBwcH6awdpc+xXl4BAQGYOXOmyU4Vrq546IZIBj169MCBAweKXLTcwsICYWFhWLJkiZk6qzoOHjyI9u3bM+RNgHv0REQKxz16IiKFY9ATESkcg56ISOEY9ERECsegJyJSOAY9EZHC/R9IWfZmJSUbyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "colors = plt.cm.get_cmap(\"Dark2\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.hist(\n",
    "    model.predict_proba(X_test)[:,1],\n",
    "    range=(0, 1),\n",
    "    bins=10,\n",
    "    label=\"GP\",\n",
    "    color=colors(1),\n",
    "    )\n",
    "ax.set(title=\"GPC-Matern-Test\", xlabel=\"Predicted probability(positive class)\", ylabel=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_timeDelta_Seconds__root_mean_square</th>\n",
       "      <th>Total_timeDelta_Seconds__mean</th>\n",
       "      <th>Total_timeDelta_Seconds__quantile__q_0.7</th>\n",
       "      <th>Total_timeDelta_Seconds__quantile__q_0.6</th>\n",
       "      <th>Total_timeDelta_Seconds__mean_abs_change</th>\n",
       "      <th>Total_timeDelta_Seconds__quantile__q_0.8</th>\n",
       "      <th>Total_timeDelta_Seconds__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.0</th>\n",
       "      <th>Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0</th>\n",
       "      <th>Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2</th>\n",
       "      <th>Total_timeDelta_Seconds__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>milking_times__large_standard_deviation__r_0.2</th>\n",
       "      <th>Age__absolute_sum_of_changes</th>\n",
       "      <th>milking_times__number_peaks__n_3</th>\n",
       "      <th>milking_times__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"</th>\n",
       "      <th>DaysInMilk__fft_coefficient__attr_\"real\"__coeff_68</th>\n",
       "      <th>BreedName_1</th>\n",
       "      <th>BreedName_2</th>\n",
       "      <th>BreedName_4</th>\n",
       "      <th>BreedName_99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.040361</td>\n",
       "      <td>-1.052863</td>\n",
       "      <td>-1.044957</td>\n",
       "      <td>-1.026876</td>\n",
       "      <td>-1.032387</td>\n",
       "      <td>-1.105493</td>\n",
       "      <td>-1.032387</td>\n",
       "      <td>-0.617057</td>\n",
       "      <td>-0.604327</td>\n",
       "      <td>-0.606794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>0.141238</td>\n",
       "      <td>-1.455100</td>\n",
       "      <td>0.638454</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.671826</td>\n",
       "      <td>2.183100</td>\n",
       "      <td>1.493171</td>\n",
       "      <td>1.562288</td>\n",
       "      <td>2.132024</td>\n",
       "      <td>1.807215</td>\n",
       "      <td>2.132024</td>\n",
       "      <td>1.331007</td>\n",
       "      <td>2.399062</td>\n",
       "      <td>3.831282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>-1.538254</td>\n",
       "      <td>-1.455100</td>\n",
       "      <td>1.640353</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.343801</td>\n",
       "      <td>-0.478895</td>\n",
       "      <td>-0.609450</td>\n",
       "      <td>-0.648323</td>\n",
       "      <td>-0.377595</td>\n",
       "      <td>-0.563320</td>\n",
       "      <td>-0.377595</td>\n",
       "      <td>-0.520889</td>\n",
       "      <td>-0.494788</td>\n",
       "      <td>-0.318304</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>1.238049</td>\n",
       "      <td>-1.063017</td>\n",
       "      <td>-0.792830</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.636363</td>\n",
       "      <td>3.097751</td>\n",
       "      <td>3.038055</td>\n",
       "      <td>2.773486</td>\n",
       "      <td>3.344164</td>\n",
       "      <td>3.524035</td>\n",
       "      <td>3.344164</td>\n",
       "      <td>4.127197</td>\n",
       "      <td>1.691970</td>\n",
       "      <td>1.799513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>-1.538254</td>\n",
       "      <td>-1.259059</td>\n",
       "      <td>0.638454</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.328595</td>\n",
       "      <td>-0.216554</td>\n",
       "      <td>-0.058725</td>\n",
       "      <td>-0.097482</td>\n",
       "      <td>-0.275922</td>\n",
       "      <td>-0.030931</td>\n",
       "      <td>-0.275922</td>\n",
       "      <td>-0.255325</td>\n",
       "      <td>-0.383424</td>\n",
       "      <td>-0.447120</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>-0.441443</td>\n",
       "      <td>-1.651141</td>\n",
       "      <td>0.352197</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-0.591009</td>\n",
       "      <td>-0.654956</td>\n",
       "      <td>-0.670955</td>\n",
       "      <td>-0.708766</td>\n",
       "      <td>-0.588152</td>\n",
       "      <td>-0.632789</td>\n",
       "      <td>-0.588152</td>\n",
       "      <td>-0.507241</td>\n",
       "      <td>-0.480969</td>\n",
       "      <td>-0.463305</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>1.203774</td>\n",
       "      <td>-0.278852</td>\n",
       "      <td>-0.300620</td>\n",
       "      <td>-0.560212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-0.938013</td>\n",
       "      <td>-0.998320</td>\n",
       "      <td>-1.044877</td>\n",
       "      <td>-1.035654</td>\n",
       "      <td>-0.932922</td>\n",
       "      <td>-1.005204</td>\n",
       "      <td>-0.932922</td>\n",
       "      <td>-0.607456</td>\n",
       "      <td>-0.580659</td>\n",
       "      <td>-0.575167</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>0.621093</td>\n",
       "      <td>0.897396</td>\n",
       "      <td>0.693267</td>\n",
       "      <td>-0.599109</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.738820</td>\n",
       "      <td>-0.847421</td>\n",
       "      <td>-0.930653</td>\n",
       "      <td>-0.919554</td>\n",
       "      <td>-0.831356</td>\n",
       "      <td>-0.871078</td>\n",
       "      <td>-0.831356</td>\n",
       "      <td>-0.598774</td>\n",
       "      <td>-0.592489</td>\n",
       "      <td>-0.502985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>1.375150</td>\n",
       "      <td>0.309272</td>\n",
       "      <td>-1.219308</td>\n",
       "      <td>-0.747028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-0.739600</td>\n",
       "      <td>-0.681753</td>\n",
       "      <td>-0.666603</td>\n",
       "      <td>-0.588145</td>\n",
       "      <td>-0.771759</td>\n",
       "      <td>-0.694471</td>\n",
       "      <td>-0.771759</td>\n",
       "      <td>-0.549616</td>\n",
       "      <td>-0.471381</td>\n",
       "      <td>-0.559385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855186</td>\n",
       "      <td>1.409426</td>\n",
       "      <td>0.309272</td>\n",
       "      <td>-0.976547</td>\n",
       "      <td>-0.733278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-0.913186</td>\n",
       "      <td>-0.940307</td>\n",
       "      <td>-0.966793</td>\n",
       "      <td>-0.952934</td>\n",
       "      <td>-0.900540</td>\n",
       "      <td>-0.966230</td>\n",
       "      <td>-0.900540</td>\n",
       "      <td>-0.604145</td>\n",
       "      <td>-0.585625</td>\n",
       "      <td>-0.576851</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.169336</td>\n",
       "      <td>0.895295</td>\n",
       "      <td>0.113231</td>\n",
       "      <td>-0.155242</td>\n",
       "      <td>-0.934079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows  991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Total_timeDelta_Seconds__root_mean_square  Total_timeDelta_Seconds__mean  \\\n",
       "id                                                                              \n",
       "1                                    -1.040361                      -1.052863   \n",
       "2                                     2.671826                       2.183100   \n",
       "3                                    -0.343801                      -0.478895   \n",
       "4                                     2.636363                       3.097751   \n",
       "5                                    -0.328595                      -0.216554   \n",
       "..                                         ...                            ...   \n",
       "112                                  -0.591009                      -0.654956   \n",
       "113                                  -0.938013                      -0.998320   \n",
       "114                                  -0.738820                      -0.847421   \n",
       "115                                  -0.739600                      -0.681753   \n",
       "116                                  -0.913186                      -0.940307   \n",
       "\n",
       "     Total_timeDelta_Seconds__quantile__q_0.7  \\\n",
       "id                                              \n",
       "1                                   -1.044957   \n",
       "2                                    1.493171   \n",
       "3                                   -0.609450   \n",
       "4                                    3.038055   \n",
       "5                                   -0.058725   \n",
       "..                                        ...   \n",
       "112                                 -0.670955   \n",
       "113                                 -1.044877   \n",
       "114                                 -0.930653   \n",
       "115                                 -0.666603   \n",
       "116                                 -0.966793   \n",
       "\n",
       "     Total_timeDelta_Seconds__quantile__q_0.6  \\\n",
       "id                                              \n",
       "1                                   -1.026876   \n",
       "2                                    1.562288   \n",
       "3                                   -0.648323   \n",
       "4                                    2.773486   \n",
       "5                                   -0.097482   \n",
       "..                                        ...   \n",
       "112                                 -0.708766   \n",
       "113                                 -1.035654   \n",
       "114                                 -0.919554   \n",
       "115                                 -0.588145   \n",
       "116                                 -0.952934   \n",
       "\n",
       "     Total_timeDelta_Seconds__mean_abs_change  \\\n",
       "id                                              \n",
       "1                                   -1.032387   \n",
       "2                                    2.132024   \n",
       "3                                   -0.377595   \n",
       "4                                    3.344164   \n",
       "5                                   -0.275922   \n",
       "..                                        ...   \n",
       "112                                 -0.588152   \n",
       "113                                 -0.932922   \n",
       "114                                 -0.831356   \n",
       "115                                 -0.771759   \n",
       "116                                 -0.900540   \n",
       "\n",
       "     Total_timeDelta_Seconds__quantile__q_0.8  \\\n",
       "id                                              \n",
       "1                                   -1.105493   \n",
       "2                                    1.807215   \n",
       "3                                   -0.563320   \n",
       "4                                    3.524035   \n",
       "5                                   -0.030931   \n",
       "..                                        ...   \n",
       "112                                 -0.632789   \n",
       "113                                 -1.005204   \n",
       "114                                 -0.871078   \n",
       "115                                 -0.694471   \n",
       "116                                 -0.966230   \n",
       "\n",
       "     Total_timeDelta_Seconds__change_quantiles__f_agg_\"mean\"__isabs_True__qh_1.0__ql_0.0  \\\n",
       "id                                                                                         \n",
       "1                                            -1.032387                                     \n",
       "2                                             2.132024                                     \n",
       "3                                            -0.377595                                     \n",
       "4                                             3.344164                                     \n",
       "5                                            -0.275922                                     \n",
       "..                                                 ...                                     \n",
       "112                                          -0.588152                                     \n",
       "113                                          -0.932922                                     \n",
       "114                                          -0.831356                                     \n",
       "115                                          -0.771759                                     \n",
       "116                                          -0.900540                                     \n",
       "\n",
       "     Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.8__ql_0.0  \\\n",
       "id                                                                                        \n",
       "1                                            -0.617057                                    \n",
       "2                                             1.331007                                    \n",
       "3                                            -0.520889                                    \n",
       "4                                             4.127197                                    \n",
       "5                                            -0.255325                                    \n",
       "..                                                 ...                                    \n",
       "112                                          -0.507241                                    \n",
       "113                                          -0.607456                                    \n",
       "114                                          -0.598774                                    \n",
       "115                                          -0.549616                                    \n",
       "116                                          -0.604145                                    \n",
       "\n",
       "     Total_timeDelta_Seconds__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.2  \\\n",
       "id                                                                                        \n",
       "1                                            -0.604327                                    \n",
       "2                                             2.399062                                    \n",
       "3                                            -0.494788                                    \n",
       "4                                             1.691970                                    \n",
       "5                                            -0.383424                                    \n",
       "..                                                 ...                                    \n",
       "112                                          -0.480969                                    \n",
       "113                                          -0.580659                                    \n",
       "114                                          -0.592489                                    \n",
       "115                                          -0.471381                                    \n",
       "116                                          -0.585625                                    \n",
       "\n",
       "     Total_timeDelta_Seconds__variance  ...  \\\n",
       "id                                      ...   \n",
       "1                            -0.606794  ...   \n",
       "2                             3.831282  ...   \n",
       "3                            -0.318304  ...   \n",
       "4                             1.799513  ...   \n",
       "5                            -0.447120  ...   \n",
       "..                                 ...  ...   \n",
       "112                          -0.463305  ...   \n",
       "113                          -0.575167  ...   \n",
       "114                          -0.502985  ...   \n",
       "115                          -0.559385  ...   \n",
       "116                          -0.576851  ...   \n",
       "\n",
       "     milking_times__large_standard_deviation__r_0.2  \\\n",
       "id                                                    \n",
       "1                                          0.855186   \n",
       "2                                          0.855186   \n",
       "3                                         -1.169336   \n",
       "4                                          0.855186   \n",
       "5                                         -1.169336   \n",
       "..                                              ...   \n",
       "112                                       -1.169336   \n",
       "113                                       -1.169336   \n",
       "114                                        0.855186   \n",
       "115                                        0.855186   \n",
       "116                                       -1.169336   \n",
       "\n",
       "     Age__absolute_sum_of_changes  milking_times__number_peaks__n_3  \\\n",
       "id                                                                    \n",
       "1                        0.141238                         -1.455100   \n",
       "2                       -1.538254                         -1.455100   \n",
       "3                        1.238049                         -1.063017   \n",
       "4                       -1.538254                         -1.259059   \n",
       "5                       -0.441443                         -1.651141   \n",
       "..                            ...                               ...   \n",
       "112                      1.203774                         -0.278852   \n",
       "113                      0.621093                          0.897396   \n",
       "114                      1.375150                          0.309272   \n",
       "115                      1.409426                          0.309272   \n",
       "116                      0.895295                          0.113231   \n",
       "\n",
       "     milking_times__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"  \\\n",
       "id                                                                             \n",
       "1                                             0.638454                         \n",
       "2                                             1.640353                         \n",
       "3                                            -0.792830                         \n",
       "4                                             0.638454                         \n",
       "5                                             0.352197                         \n",
       "..                                                 ...                         \n",
       "112                                          -0.300620                         \n",
       "113                                           0.693267                         \n",
       "114                                          -1.219308                         \n",
       "115                                          -0.976547                         \n",
       "116                                          -0.155242                         \n",
       "\n",
       "     DaysInMilk__fft_coefficient__attr_\"real\"__coeff_68  BreedName_1  \\\n",
       "id                                                                     \n",
       "1                                             0.079254           0.0   \n",
       "2                                             0.079254           0.0   \n",
       "3                                             0.079254           0.0   \n",
       "4                                             0.079254           0.0   \n",
       "5                                             0.079254           0.0   \n",
       "..                                                 ...           ...   \n",
       "112                                          -0.560212           0.0   \n",
       "113                                          -0.599109           1.0   \n",
       "114                                          -0.747028           0.0   \n",
       "115                                          -0.733278           1.0   \n",
       "116                                          -0.934079           1.0   \n",
       "\n",
       "     BreedName_2  BreedName_4  BreedName_99  label  \n",
       "id                                                  \n",
       "1            0.0          1.0           0.0      0  \n",
       "2            0.0          0.0           1.0      0  \n",
       "3            1.0          0.0           0.0      0  \n",
       "4            0.0          0.0           1.0      0  \n",
       "5            1.0          0.0           0.0      0  \n",
       "..           ...          ...           ...    ...  \n",
       "112          1.0          0.0           0.0      0  \n",
       "113          0.0          0.0           0.0      1  \n",
       "114          1.0          0.0           0.0      1  \n",
       "115          0.0          0.0           0.0      0  \n",
       "116          0.0          0.0           0.0      1  \n",
       "\n",
       "[116 rows x 991 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prediction, std_prediction = model.predict(X, return_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(\n",
    "    X_train, y_train.values.ravel()\n",
    "    pred\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7857ada9c2c05e5ee75d334d60fb77cca110ad03375c3b02029444557fa6212d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
